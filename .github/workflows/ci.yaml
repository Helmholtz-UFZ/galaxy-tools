name: Weekly global Tool Linting and Tests
on:
  schedule:
    # Run at midnight every monday
    - cron: '0 0 * * 1'
  repository_dispatch:
    types: [run-all-tool-tests-command]
  workflow_dispatch:
env:
  GALAXY_FORK: galaxyproject
  GALAXY_BRANCH: release_25.1
  MAX_CHUNKS: 40
jobs:
  setup:
    name: Setup cache and determine changed repositories
    if: ${{ github.repository_owner == 'Helmholtz-UFZ' }}
    runs-on: ubuntu-latest
    outputs:
      galaxy-head-sha: ${{ steps.get-galaxy-sha.outputs.galaxy-head-sha }}
      fork: ${{ steps.get-fork-branch.outputs.fork }}
      branch: ${{ steps.get-fork-branch.outputs.branch }}
      repository-list: ${{ steps.discover.outputs.repository-list }}
      chunk-count: ${{ steps.discover.outputs.chunk-count }}
      chunk-list: ${{ steps.discover.outputs.chunk-list }}
    strategy:
      matrix:
        python-version: ['3.11']
    steps:
    - name: Add reaction
      if: ${{ github.event.client_payload.slash_command.command == 'run-all-tool-tests' }}
      uses: peter-evans/create-or-update-comment@v5
      with:
        token: ${{ secrets.PAT }}
        repository: ${{ github.event.client_payload.github.payload.repository.full_name }}
        comment-id: ${{ github.event.client_payload.github.payload.comment.id }}
        reactions: hooray
    - name: Set galaxy fork and branch
      id: get-fork-branch
      run: |
        TMP="${{ github.event.client_payload.slash_command.args.named.fork }}"
        echo "fork=${TMP:-$GALAXY_FORK}" >> $GITHUB_OUTPUT
        TMP="${{ github.event.client_payload.slash_command.args.named.branch }}"
        echo "branch=${TMP:-$GALAXY_BRANCH}" >> $GITHUB_OUTPUT
    - name: Determine latest commit in the Galaxy repo
      id: get-galaxy-sha
      run: echo "galaxy-head-sha=$(git ls-remote https://github.com/${{ steps.get-fork-branch.outputs.fork }}/galaxy refs/heads/${{ steps.get-fork-branch.outputs.branch }} | cut -f1)" >> $GITHUB_OUTPUT
    - uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
    - name: Cache .cache/pip
      uses: actions/cache@v5
      id: cache-pip
      with:
        path: ~/.cache/pip
        key: pip_cache_py_${{ matrix.python-version }}_gxy_${{ steps.get-galaxy-sha.outputs.galaxy-head-sha }}
    # Install the `wheel` package so that when installing other packages which
    # are not available as wheels, pip will build a wheel for them, which can be cached.
    - name: Install wheel
      run: pip install wheel
    - uses: actions/checkout@v6
      with:
        persist-credentials: false
    - name: Fake a Planemo run to update cache and determine commit range, repositories, and chunks
      uses: galaxyproject/planemo-ci-action@v1
      id: discover
      with:
        create-cache: ${{ steps.cache-pip.outputs.cache-hit != 'true' || steps.cache-planemo.outputs.cache-hit != 'true' }}
        galaxy-fork: ${{ steps.get-fork-branch.outputs.fork }}
        galaxy-branch: ${{ steps.get-fork-branch.outputs.branch }}
        max-chunks: ${{ env.MAX_CHUNKS }}
        python-version: ${{ matrix.python-version }}
    - name: Show repository list
      run: echo '${{ steps.discover.outputs.repository-list }}'
    - name: Show chunks
      run: |
        echo 'Using ${{ steps.discover.outputs.chunk-count }} chunks (${{ steps.discover.outputs.chunk-list }})'

  lint:
    name: Lint tool-list
    needs: setup
    if: ${{ needs.setup.outputs.repository-list != '' || needs.setup.outputs.tool-list != '' }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11']
    steps:
    - uses: actions/checkout@v6
      with:
        persist-credentials: false
    - uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
    - name: Cache .cache/pip
      uses: actions/cache@v5
      id: cache-pip
      with:
        path: ~/.cache/pip
        key: pip_cache_py_${{ matrix.python-version }}_gxy_${{ needs.setup.outputs.galaxy-head-sha }}
    - name: Planemo lint
      uses: galaxyproject/planemo-ci-action@v1
      id: lint
      with:
        mode: lint
        fail-level: warn
        repository-list: ${{ needs.setup.outputs.repository-list }}
        tool-list: ${{ needs.setup.outputs.tool-list }}
        additional-planemo-options: --biocontainers --skip version_bumped
    - uses: actions/upload-artifact@v6
      if: ${{ failure() }}
      with:
        name: 'Tool linting output'
        path: lint_report.txt

  test:
    name: Test tools
    # This job runs on Linux
    runs-on: ubuntu-latest
    needs: setup
    if: ${{ needs.setup.outputs.repository-list != '' }}
    strategy:
      fail-fast: false
      matrix:
        chunk: ${{ fromJson(needs.setup.outputs.chunk-list) }}
        python-version: ['3.11']
    services:
      postgres:
        image: postgres:11
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        ports:
          - 5432:5432
    steps:
    - uses: actions/checkout@v6
      with:
        persist-credentials: false
    - uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
    - name: Cache .cache/pip
      uses: actions/cache@v5
      id: cache-pip
      with:
        path: ~/.cache/pip
        key: pip_cache_py_${{ matrix.python-version }}_gxy_${{ needs.setup.outputs.galaxy-head-sha }}
    - name: Get number of CPU cores
      uses: SimenB/github-actions-cpu-cores@v2
      id: cpu-cores
    - name: Clean dotnet folder for space
      run: rm -Rf /usr/share/dotnet

    - name: Check for folder changes
      id: filter
      run: |
        pip install planemo
        echo "${{ needs.setup.outputs.repository-list }}" > repository_list.txt 
        mapfile -t REPO_ARRAY < repository_list.txt
        planemo ci_find_tools --chunk_count "${{ needs.setup.outputs.chunk-count }}" --chunk "${{ matrix.chunk }}" --output tool_list_chunk.txt "${REPO_ARRAY[@]}"

        if grep -q scripting tool_list_chunk.txt; then
          echo "scripting=true" >> $GITHUB_OUTPUT
        else
          echo "scripting=false" >> $GITHUB_OUTPUT
        fi
        if grep -q lambdaminer tool_list_chunk.txt; then
          echo "lambdaminer=true" >> $GITHUB_OUTPUT
        else
          echo "lambdaminer=false" >> $GITHUB_OUTPUT
        fi
        if grep -q omero tool_list_chunk.txt; then
          echo "omero=true" >> $GITHUB_OUTPUT
        else
          echo "omero=false" >> $GITHUB_OUTPUT
        fi
        if egrep -q "virsorter|phabox|genomad|dfast" tool_list_chunk.txt; then
          echo "testdata=true" >> $GITHUB_OUTPUT
          echo "tool_list_chunk<<EOF" >> $GITHUB_OUTPUT
          cat tool_list_chunk.txt >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
        else
          echo "testdata=false" >> $GITHUB_OUTPUT
        fi
        cat $GITHUB_OUTPUT

    # the following 2 steps are needed for testing the scripting tool
    - name: Install Apptainer's singularity
      if: steps.filter.outputs.scripting == 'true'
      uses: eWaterCycle/setup-apptainer@v2
    - name: Symlink singularity
      if: steps.filter.outputs.scripting == 'true'
      run: ln -s $(which apptainer) $(dirname apptainer)/singularity
    - name: Install containers
      if: steps.filter.outputs.scripting == 'true'
      run: |
        singularity pull --dir /tmp docker://rocker/tidyverse
        singularity pull --dir /tmp docker://python:3.10-slim

    # Set up the lambda-miner database
    - name: Create a database in the postgres for lambda-miner
      if: steps.filter.outputs.lambdaminer == 'true'
      run: |
        PGPASSWORD=postgres psql -h localhost -U postgres -c "CREATE DATABASE lmdb;"
        PGPASSWORD=postgres psql -h localhost -U postgres -d lmdb -q -f ./.github/lambdaminer/build.sql
        sleep 10
        PGPASSWORD=postgres psql -h localhost -U postgres -d lmdb -c "SELECT * FROM public.instrument;"

    # Start OMERO
    - name: Start OMERO
      if: steps.filter.outputs.omero == 'true'
      uses: sudo-bot/action-docker-compose@latest
      with:
        cli-args: "-f .github/omero-docker-compose.yml up -d"

    # Upload a dummy dataset in OMERO
    - name: Install dependencies and upload a OMERO dummy dataset
      if: steps.filter.outputs.omero == 'true'
      run: |
        echo "Waiting for OMERO to be ready..."
        sleep 60
        pip install https://github.com/glencoesoftware/zeroc-ice-py-linux-x86_64/releases/download/20240202/zeroc_ice-3.6.5-cp311-cp311-manylinux_2_28_x86_64.whl
        pip install omero-py==5.19.4
        pip install omero-metadata
        omero login -s localhost -u root -w omero -p 6064
        PID=$(omero obj new Project name='test_prj')
        DID=$(omero obj new Dataset name='test_dts')
        omero obj new ProjectDatasetLink parent=$PID child=$DID
        omero import -d $DID .github/dummy-dts-omero
        omero tag create --name test_tag --desc 'description of my_tag'
        omero tag link Image:1 1
        echo "Created the dummy dataset into OMERO"
        DID_HCS=$(omero obj new Dataset name='test_hcs_dts')
        omero import -d $DID_HCS .github/dummy-hcs-omero
        echo "Created the hcs dummy dataset into OMERO"
        omero upload .github/dummy_omero_tabs/attachment.tsv
        omero upload .github/dummy_omero_tabs/attachment.tsv
        omero upload .github/dummy_omero_tabs/attachment.tsv
        omero obj new FileAnnotation file=OriginalFile:110
        omero obj new FileAnnotation file=OriginalFile:111
        omero obj new FileAnnotation file=OriginalFile:112
        omero metadata populate --file .github/dummy_omero_tabs/dummy-bulkmap.csv $DID
        omero metadata populate --file .github/dummy_omero_tabs/dummy-bulkmap.csv $DID
        omero metadata populate --context bulkmap --cfg .github/dummy_omero_tabs/dummy-bulkmap.yml $DID
        echo "Uploaded Attachments, KV pairs and Tables"

    # download or create large test data via script
    - name: Create test data
      if: steps.filter.outputs.testdata == 'true'
      run: |
          set -x
          echo "${{ steps.filter.outputs.tool_list_chunk }}" >> tool_list_chunk.txt
          cat tool_list_chunk.txt | sed 's@/[^/]*$@@' | sort -i > repository_list_chunk.txt
          while read repo
          do
              echo "executing test-data.sh for $repo"
              if [ -x $repo/test-data.sh ]; then
                  cd $repo
                  ./test-data.sh
              fi
          done < repository_list_chunk.txt

    - name: Planemo test
      uses: galaxyproject/planemo-ci-action@v1
      id: test
      with:
        mode: test
        repository-list: ${{ needs.setup.outputs.repository-list }}
        galaxy-fork: ${{ needs.setup.outputs.fork }}
        galaxy-branch: ${{ needs.setup.outputs.branch }}
        additional-planemo-options: --docker_run_extra_arguments '--add-host=host.docker.internal:host-gateway'
        chunk: ${{ matrix.chunk }}
        chunk-count: ${{ needs.setup.outputs.chunk-count }}
        galaxy-slots: ${{ steps.cpu-cores.outputs.count }}
        # Limit each test to 15 minutes
        test_timeout: 900
    - uses: actions/upload-artifact@v6
      with:
        name: 'Tool test output ${{ matrix.chunk }}'
        path: upload

  # - combine the results of the test chunks (which will never fail due
  #   to `|| true`) and create a global test report as json and html which
  #   is provided as artifact
  # - check if any tool test actually failed (by lookup in the combined json)
  #   and fail this step if this is the case
  combine_outputs:
    name: Combine chunked test results
    needs: [setup, test]
    strategy:
      matrix:
        python-version: ['3.11']
    # This job runs on Linux
    runs-on: ubuntu-latest
    steps:
    - uses: actions/download-artifact@v7
      with:
        path: artifacts
    - uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
    - name: Cache .cache/pip
      uses: actions/cache@v5
      id: cache-pip
      with:
        path: ~/.cache/pip
        key: pip_cache_py_${{ matrix.python-version }}_gxy_${{ needs.setup.outputs.galaxy-head-sha }}
    - name: Combine outputs
      uses: galaxyproject/planemo-ci-action@v1
      id: combine
      with:
        mode: combine
        html-report: true
        markdown-report: true
    - uses: actions/upload-artifact@v6
      with:
        name: 'All tool test results'
        path: upload
    - run: cat upload/tool_test_output.md >> $GITHUB_STEP_SUMMARY
    - name: Create URL to the run output
      if: ${{ github.event.client_payload.slash_command.command == 'run-all-tool-tests' }}
      id: vars
      run: echo "run-url=https://github.com/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID" >> $GITHUB_OUTPUT

    - name: Create comment
      if: ${{ github.event.client_payload.slash_command.command == 'run-all-tool-tests' }}
      uses: peter-evans/create-or-update-comment@v5
      with:
        token: ${{ secrets.PAT }}
        repository: ${{ github.event.client_payload.github.payload.repository.full_name }}
        issue-number: ${{ github.event.client_payload.github.payload.issue.number }}
        body: |
          Summary:

          ${{ steps.combine.outputs.statistics }}

          [Find all tool test results here][1]

          [1]: ${{ steps.vars.outputs.run-url }}
    - name: Check outputs
      uses: galaxyproject/planemo-ci-action@v1
      id: check
      with:
        mode: check
