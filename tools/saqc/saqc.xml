<tool name="SaQC" id="saqc" version="@TOOL_VERSION@+galaxy@VERSION_SUFFIX@" profile="22.01">
  <description>quality control pipelines for environmental sensor data</description>
  <macros>
    <import>macros.xml</import>
    <import>test_macros.xml</import>
  </macros>
  <expand macro="requirements"/>
  <version_command><![CDATA[python -c 'import saqc; print(saqc.__version__)']]></version_command>
  <command><![CDATA[#set $first_data_file = $data[0]
#if str($run_test_mode) == "true":
  '$__tool_directory__'/json_to_saqc_config.py '$param_conf' '$first_data_file' > config.csv
#else
  '$__tool_directory__'/json_to_saqc_config.py '$param_conf' '$first_data_file' > config.csv &&
  #for $i, $d in enumerate($data)
    ##maybe link to element_identifier
    ln -s '$d' '${i}.csv' &&
  #end for
  saqc --config config.csv
  #for $i, $d in enumerate($data)
    --data '${i}.csv'
  #end for
  --outfile output.csv
#end if]]></command>
  <configfiles>
    <inputs name="param_conf"/>
  </configfiles>
  <inputs>
    <param argument="--data" type="data" label="Input table(s)" format="csv" multiple="true"/>
    <param name="run_test_mode" type="hidden" value="false" label=""/>
    <repeat name="methods_repeat" title="Methods (add multiple QC steps)">
      <conditional name="module_cond" label="SaQC Module">
        <param name="module_select" type="select" label="Select SaQC module">
          <option value="breaks">breaks: Detecting breaks in data</option>
          <option value="changepoints">changepoints: changepoints</option>
          <option value="constants">constants: constants</option>
          <option value="curvefit">curvefit: curvefit</option>
          <option value="drift">drift: drift</option>
          <option value="flagtools">flagtools: flagtools</option>
          <option value="generic">generic: generic</option>
          <option value="interpolation">interpolation: interpolation</option>
          <option value="noise">noise: noise</option>
          <option value="outliers">outliers: outliers</option>
          <option value="pattern">pattern: pattern</option>
          <option value="resampling">resampling: resampling</option>
          <option value="residuals">residuals: residuals</option>
          <option value="rolling">rolling: rolling</option>
          <option value="scores">scores: scores</option>
          <option value="tools">tools: tools</option>
          <option value="transformation">transformation: transformation</option>
        </param>
        <when value="breaks">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="flagIsolated">flagIsolated: Find and flag temporally isolated groups of data</option>
              <option value="flagJumps">flagJumps: Flag jumps and drops in data</option>
              <option value="flagMissing">flagMissing: deprecated:: 2.7.0</option>
              <option value="flagNAN">flagNAN: Flag NaNs in data</option>
            </param>
            <when value="flagIsolated">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="gap_window" type="text" label="gap_window" help="str Minimum gap size required before and after a data group to consider it isolated. See conditions (2) and (3) below (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="group_window" type="text" label="group_window" help="str Maximum size of a data chunk to consider it a candidate for an isolated group. Data chunks larger than this are ignored. This does not include the possible gaps surrounding it. See condition (1) below (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagJumps">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="thresh" type="float" label="thresh" help="float Threshold by which the mean of data must jump to trigger flagging" min="0"/>
              <param argument="window" type="text" label="window" help="str Size of the two rolling windows. Determines the number of timestamps used for calculating the mean in each window. Windows should be chosen large enough to obtain a reliable mean. But not too large as well, since the window size implies a lower bound for the detection resolution. Jumps exceeding `thresh` but being apart from each other by less than 3/4 of the window size may not be detected reliably (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="min_periods" type="integer" value="0" optional="true" label="min_periods" help="int Minimum number of timestamps in `window` required to calculate a valid mean. If no valid mean for the window can be calculated, flagging wont be triggered for the associated change point" min="0"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
              <param argument="dfilter" type="float" value="-inf" optional="true" label="dfilter" help="`Any`, optional Defines which observations will be masked based on the already existing flags. Any data point with a flag equal or worse to this threshold will be passed as ``NaN`` to the function. Defaults to the ``DFILTER_ALL`` value of the translation scheme"/>
            </when>
            <when value="flagMissing">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
              <param argument="dfilter" type="float" value="-inf" optional="true" label="dfilter" help="`Any`, optional Defines which observations will be masked based on the already existing flags. Any data point with a flag equal or worse to this threshold will be passed as ``NaN`` to the function. Defaults to the ``DFILTER_ALL`` value of the translation scheme"/>
            </when>
            <when value="flagNAN">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
              <param argument="dfilter" type="float" value="-inf" optional="true" label="dfilter" help="`Any`, optional Defines which observations will be masked based on the already existing flags. Any data point with a flag equal or worse to this threshold will be passed as ``NaN`` to the function. Defaults to the ``DFILTER_ALL`` value of the translation scheme"/>
            </when>
          </conditional>
        </when>
        <when value="changepoints">
          <param name="changepoints_no_methods_conditional" type="text" value="Could not generate method selection for module 'changepoints'." label="Notice"/>
        </when>
        <when value="constants">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="flagByVariance">flagByVariance: Flag low-variance data</option>
              <option value="flagConstants">flagConstants: Flag constant data values</option>
            </param>
            <when value="flagByVariance">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="window" type="text" label="window" help="Size of the moving window. This is the number of observations used for calculating the statistic. Each window will be a fixed size. If its an offset then this will be the time period of each window. Each window will be sized, based on the number of observations included in the time-period (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="thresh" type="float" label="thresh" help="Maximum total variance allowed per window" min="0"/>
              <param argument="maxna" type="integer" optional="true" label="maxna" help="Maximum number of NaNs allowed in window. If more NaNs are present, the window is not flagged" min="0"/>
              <param argument="maxna_group" type="integer" optional="true" label="maxna_group" help="Same as `maxna` but for consecutive NaNs" min="0"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagConstants">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="thresh" type="float" label="thresh" help="float Maximum total change allowed per window" min="0"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="int or str Size of the rolling window. If an integer is passed, it represents the number of timestamps per window. If an offset string is passed, it represents the windows total temporal extent">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">(Integer &gt;= 1)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" label="window" help="int or str Size of the rolling window. If an integer is passed, it represents the number of timestamps per window. If an offset string is passed, it represents the windows total temporal extent (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" label="window" help="int or str Size of the rolling window. If an integer is passed, it represents the number of timestamps per window. If an offset string is passed, it represents the windows total temporal extent" min="1"/>
                </when>
              </conditional>
              <param argument="min_periods" type="integer" value="2" optional="true" label="min_periods" help="int Minimum number of valid timestamps that are necessary to be present in any window, in order to trigger condition testing for this window. Windows with fewer timestamps are skipped. Must be  = 2, because a single value is always considered constant" min="0"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
          </conditional>
        </when>
        <when value="curvefit">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="fitLowpassFilter">fitLowpassFilter: Fits the data using the butterworth filter</option>
              <option value="fitMomentFM">fitMomentFM: Fits the data by reconstructing it with the Moment Foundational Timeseries Model (MomentFM)</option>
              <option value="fitPolynomial">fitPolynomial: Fit a polynomial model to the data</option>
            </param>
            <when value="fitLowpassFilter">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="cutoff_cond" label="cutoff">
                <param name="cutoff_selector" type="select" label="Choose type for 'cutoff'" help="The cutoff-frequency, either an offset freq string, or expressed in multiples of the sampling rate">
                  <option value="type_0">(Float &gt;= 0)</option>
                  <option value="type_1">Frequency String</option>
                </param>
                <when value="type_0">
                  <param argument="cutoff" type="float" label="cutoff" help="The cutoff-frequency, either an offset freq string, or expressed in multiples of the sampling rate" min="0"/>
                </when>
                <when value="type_1">
                  <param argument="cutoff" type="text" label="cutoff" help="The cutoff-frequency, either an offset freq string, or expressed in multiples of the sampling rate (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
              </conditional>
              <param argument="nyq" type="float" value="0.5" optional="true" label="nyq" help="The niquist-frequency. expressed in multiples if the sampling rate" min="0"/>
              <param argument="filter_order" type="integer" value="2" optional="true" label="filter_order" help="" min="1"/>
              <param argument="fill_method" type="select" value="linear" optional="true" label="fill_method" help="Fill method to be applied on the data before filtering (butterfilter cant handle ''np.nan''). See documentation of pandas.Series.interpolate method for details on the methods associated with the different keywords">
                <option value="linear">linear</option>
                <option value="nearest">nearest</option>
                <option value="zero">zero</option>
                <option value="slinear">slinear</option>
                <option value="quadratic">quadratic</option>
                <option value="cubic">cubic</option>
                <option value="spline">spline</option>
                <option value="barycentric">barycentric</option>
                <option value="polynomial">polynomial</option>
              </param>
            </when>
            <when value="fitMomentFM">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="ratio" type="integer" value="4" optional="true" label="ratio" help="The number of samples generated for any values reconstruction. Must be a divisor of `context`. Effectively controlls the stride-width of the reconstruction window through the data"/>
              <param argument="context" type="integer" value="512" optional="true" label="context" help="size of the context window with regard to wich any value is reconstructed"/>
              <param argument="agg" type="select" value="mean" optional="true" label="agg" help="How to aggregate the different reconstructions for the same value. * 'center': use the value that was constructed in a window centering around the origin value * 'mean': assign the mean over all reconstructed values * 'median': assign the median over all reconstructed values * 'std': assign the standard deviation over all reconstructed values">
                <option value="center">center</option>
                <option value="mean">mean</option>
                <option value="median">median</option>
                <option value="std">std</option>
              </param>
            </when>
            <when value="fitPolynomial">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="int or str Size of the fitting window. If an integer is passed, it represents the number of timestamps in each window. If an offset string is passed, it represents the window's temporal extent. The window is centered around the timestamp being fitted. For uniformly sampled data, an odd number of timestamps is always used to constitute a window (subtracted by 1, if the total is even)">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">(Integer &gt;= 0)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" label="window" help="int or str Size of the fitting window. If an integer is passed, it represents the number of timestamps in each window. If an offset string is passed, it represents the window's temporal extent. The window is centered around the timestamp being fitted. For uniformly sampled data, an odd number of timestamps is always used to constitute a window (subtracted by 1, if the total is even) (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" label="window" help="int or str Size of the fitting window. If an integer is passed, it represents the number of timestamps in each window. If an offset string is passed, it represents the window's temporal extent. The window is centered around the timestamp being fitted. For uniformly sampled data, an odd number of timestamps is always used to constitute a window (subtracted by 1, if the total is even)" min="0"/>
                </when>
              </conditional>
              <param argument="order" type="integer" label="order" help="int Degree of the polynomial used for fitting" min="1"/>
              <param argument="min_periods" type="integer" value="0" optional="true" label="min_periods" help="int Minimum number of timestamps in a window required to perform the fit. Windows with fewer timestamps will produce NaNs. Passing 0 disables this check and may result in overfitting for sparse windows" min="0"/>
            </when>
          </conditional>
        </when>
        <when value="drift">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="assignRegimeAnomaly">assignRegimeAnomaly: A function to detect values belonging to an anomalous regime regarding modelling</option>
              <option value="correctDrift">correctDrift: The function corrects drifting behavior</option>
              <option value="correctOffset">correctOffset: Parameters</option>
              <option value="correctRegimeAnomaly">correctRegimeAnomaly: Function fits the passed model to the different regimes in data[field] and tries to correct</option>
              <option value="flagDriftFromNorm">flagDriftFromNorm: Flags data that deviates from an avarage data course</option>
              <option value="flagDriftFromReference">flagDriftFromReference: Flags data that deviates from a reference course. Deviation is measured by a</option>
              <option value="flagRegimeAnomaly">flagRegimeAnomaly: Flags anomalous regimes regarding to modelling regimes of ``field``</option>
            </param>
            <when value="assignRegimeAnomaly">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="cluster_field" type="text" label="cluster_field" help="Column in data, holding the cluster labels for the samples in field. (has to be indexed equal to field)">
                <validator type="empty_field"/>
              </param>
              <param argument="spread" type="float" label="spread" help="A threshold denoting the value level, up to wich clusters a agglomerated" min="0"/>
              <param argument="method" type="select" value="single" optional="true" label="method" help="The linkage method for hierarchical (agglomerative) clustering of the variables">
                <option value="single">single</option>
                <option value="complete">complete</option>
                <option value="average">average</option>
                <option value="weighted">weighted</option>
                <option value="centroid">centroid</option>
                <option value="median">median</option>
                <option value="ward">ward</option>
              </param>
              <param argument="metric" type="text" label="metric" help="A metric function for calculating the dissimilarity between 2 regimes. Defaults to the absolute difference in mean"/>
              <param argument="frac" type="float" value="0.5" optional="true" label="frac" help="The minimum percentage of samples, the  normal  group has to comprise to actually be the normal group. Must be in the closed interval `[0,1]`, otherwise a ValueError is raised" min="0" max="1"/>
            </when>
            <when value="correctDrift">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="maintenance_field" type="text" label="maintenance_field" help="Column holding the support-points information. The data is expected to have the following form: The index of the series represents the beginning of a maintenance event, wheras the values represent its endings">
                <validator type="empty_field"/>
              </param>
              <param argument="model" type="select" label="model" help="A model function describing the drift behavior, that is to be corrected. Either use built-in exponential or linear drift model by passing a string, or pass a custom callable. The model function must always contain the keyword parameters 'origin' and 'target'. The starting parameter must always be the parameter, by wich the data is passed to the model. After the data parameter, there can occure an arbitrary number of model calibration arguments in the signature. See the Notes section for an extensive description">
                <option value="linear">linear</option>
                <option value="exponential">exponential</option>
              </param>
              <param argument="cal_range" type="integer" value="5" optional="true" label="cal_range" help="Number of values to calculate the mean of, for obtaining the value level directly after and directly before a maintenance event. Needed for shift calibration" min="0"/>
            </when>
            <when value="correctOffset">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="max_jump" type="float" label="max_jump" help="when searching for changepoints in mean - this is the threshold a mean difference in the sliding window search must exceed to trigger changepoint detection" min="0"/>
              <param argument="spread" type="float" label="spread" help="threshold denoting the maximum, regimes are allowed to abolutely differ in their means to form the  normal group  of values" min="0"/>
              <param argument="window" type="text" label="window" help="Size of the adjacent windows that are used to search for the mean changepoints (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="min_periods" type="integer" label="min_periods" help="Minimum number of periods a search window has to contain, for the result of the changepoint detection to be considered valid" min="0"/>
              <param argument="tolerance" type="text" optional="true" label="tolerance" help="If an offset string is passed, a data chunk of length `offset` right from the start and right before the end of any regime is ignored when calculating a regimes mean for data correcture. This is to account for the unrelyability of data near the changepoints of regimes (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
              </param>
            </when>
            <when value="correctRegimeAnomaly">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="cluster_field" type="text" label="cluster_field" help="A string denoting the field in data, holding the cluster label for the data you want to correct">
                <validator type="empty_field"/>
              </param>
              <param argument="model" type="text" label="model" help="The model function to be fitted to the regimes. It must be a function of the form :math:`f(x, *p)`, where :math:`x` is the ``numpy.array`` holding the independent variables and :math:`p` are the model parameters that are to be obtained by fitting. Depending on the `x_date` parameter, independent variable x will either be the timestamps of every regime transformed to seconds from epoch, or it will be just seconds, counting the regimes length">
                <validator type="empty_field"/>
              </param>
              <param argument="tolerance" type="text" optional="true" label="tolerance" help="If an offset string is passed, a data chunk of length `offset` right at the start and right at the end is ignored when fitting the model. This is to account for the unreliability of data near the changepoints of regimes. Defaults to None (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
              </param>
              <param argument="epoch" type="boolean" label="epoch" help="If True, use  seconds from epoch  as x input to the model func, instead of  seconds from regime start " checked="false" truevalue="epoch" falsevalue=""/>
            </when>
            <when value="flagDriftFromNorm">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="window" type="text" label="window" help="Frequency, that split the data in chunks (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="spread" type="float" label="spread" help="Maximum spread allowed in the group of *normal* data. See Notes section for more details" min="0"/>
              <param argument="frac" type="float" value="0.5" optional="true" label="frac" help="Fraction defining the normal group. Use a value from the interval [0,1]. The higher the value, the more stable the algorithm will be. For values below 0.5 the results are undefined" min="0" max="1"/>
              <param argument="metric" type="text" label="metric" help="default cityblock Distance function that takes two arrays as input and returns a scalar float. This value is interpreted as the distance of the two input arrays. Defaults to the `averaged manhattan metric` (see Notes)"/>
              <param argument="method" type="select" value="single" optional="true" label="method" help="Linkage method used for hierarchical (agglomerative) clustering of the data. `method` is directly passed to ``scipy.hierarchy.linkage``. See its documentation [1] for more details. For a general introduction on hierarchical clustering see [2]">
                <option value="single">single</option>
                <option value="complete">complete</option>
                <option value="average">average</option>
                <option value="weighted">weighted</option>
                <option value="centroid">centroid</option>
                <option value="median">median</option>
                <option value="ward">ward</option>
              </param>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagDriftFromReference">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="reference" type="text" label="reference" help="Reference variable, the deviation is calculated from">
                <validator type="empty_field"/>
              </param>
              <param argument="freq" type="text" label="freq" help="Frequency, that split the data in chunks (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="thresh" type="float" label="thresh" help="Maximum deviation from reference" min="0"/>
              <param argument="metric" type="text" label="metric" help="default cityblock Distance function. Takes two arrays as input and returns a scalar float. This value is interpreted as the mutual distance of the two input arrays. Defaults to the `averaged manhattan metric` (see Notes)"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagRegimeAnomaly">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="cluster_field" type="text" label="cluster_field" help="Column in data, holding the cluster labels for the samples in field. (has to be indexed equal to field)">
                <validator type="empty_field"/>
              </param>
              <param argument="spread" type="float" label="spread" help="A threshold denoting the value level, up to wich clusters a agglomerated" min="0"/>
              <param argument="method" type="select" value="single" optional="true" label="method" help="The linkage method for hierarchical (agglomerative) clustering of the variables">
                <option value="single">single</option>
                <option value="complete">complete</option>
                <option value="average">average</option>
                <option value="weighted">weighted</option>
                <option value="centroid">centroid</option>
                <option value="median">median</option>
                <option value="ward">ward</option>
              </param>
              <param argument="metric" type="text" label="metric" help="A metric function for calculating the dissimilarity between 2 regimes. Defaults to the absolute difference in mean"/>
              <param argument="frac" type="float" value="0.5" optional="true" label="frac" help="The minimum percentage of samples, the  normal  group has to comprise to actually be the normal group. Must be in the closed interval `[0,1]`, otherwise a ValueError is raised" min="0" max="1"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
          </conditional>
        </when>
        <when value="flagtools">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="andGroup">andGroup: Logical AND operation for Flags</option>
              <option value="clearFlags">clearFlags: Assign the flag UNFLAGGED to all timestamps</option>
              <option value="flagDummy">flagDummy: Function does nothing but returning data and flags</option>
              <option value="flagManual">flagManual: Include flags listed in external data</option>
              <option value="flagUnflagged">flagUnflagged: Assign a `flag` to all timestamps</option>
              <option value="forceFlags">forceFlags: Set whole column to a flag value</option>
              <option value="orGroup">orGroup: Logical OR operation for Flags</option>
              <option value="propagateFlags">propagateFlags: Propagate already assigned flags along the date axis</option>
              <option value="transferFlags">transferFlags: Transfer flags from one field to another</option>
            </param>
            <when value="andGroup">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param name="group" type="data" optional="true" label="group" help="A collection of ``SaQC`` objects. Flag checks are performed on all ``SaQC`` objects based on the variables specified in ``field``. Whenever all monitored variables are flagged, the associated timestamps will receive a flag" format="csv" multiple="true"/>
              <param argument="target" type="data_column" optional="true" label="target" help="`SaQCFields` | `newSaQCFields` , optional Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="clearFlags">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
            </when>
            <when value="flagDummy">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
            </when>
            <when value="flagManual">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="mdata_cond" label="mdata">
                <param name="mdata_selector" type="select" label="Choose type for 'mdata'" help="Determines which values or intervals will be flagged. Supported input types:  * ``pd.Series``: Needs a datetime index and values of type:  - datetime, for `method` values `` right-closed ``, `` left-closed ``, `` closed `` - or any scalar, for `method` values `` plain ``, `` ontime ``  * ``str``: Variable holding the manual flag information. * ``pd.DataFrame``, ``DictOfSeries``: Need to provide a ``pd.Series`` with column name `field`. * ``list``, ``np.ndarray``: Only supported with `method` value `` plain `` and `mformat` value `` mflag ``">
                  <option value="type_0">Text</option>
                  <option value="type_1">Pd.Series</option>
                  <option value="type_2">Arraylike</option>
                  <option value="type_3">List</option>
                  <option value="type_4">Pd.Dataframe</option>
                </param>
                <when value="type_0">
                  <param argument="mdata" type="text" label="mdata" help="Determines which values or intervals will be flagged. Supported input types:  * ``pd.Series``: Needs a datetime index and values of type:  - datetime, for `method` values `` right-closed ``, `` left-closed ``, `` closed `` - or any scalar, for `method` values `` plain ``, `` ontime ``  * ``str``: Variable holding the manual flag information. * ``pd.DataFrame``, ``DictOfSeries``: Need to provide a ``pd.Series`` with column name `field`. * ``list``, ``np.ndarray``: Only supported with `method` value `` plain `` and `mformat` value `` mflag ``">
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="mdata" type="text" label="mdata" help="Determines which values or intervals will be flagged. Supported input types:  * ``pd.Series``: Needs a datetime index and values of type:  - datetime, for `method` values `` right-closed ``, `` left-closed ``, `` closed `` - or any scalar, for `method` values `` plain ``, `` ontime ``  * ``str``: Variable holding the manual flag information. * ``pd.DataFrame``, ``DictOfSeries``: Need to provide a ``pd.Series`` with column name `field`. * ``list``, ``np.ndarray``: Only supported with `method` value `` plain `` and `mformat` value `` mflag ``">
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_2">
                  <param argument="mdata" type="text" label="mdata" help="Determines which values or intervals will be flagged. Supported input types:  * ``pd.Series``: Needs a datetime index and values of type:  - datetime, for `method` values `` right-closed ``, `` left-closed ``, `` closed `` - or any scalar, for `method` values `` plain ``, `` ontime ``  * ``str``: Variable holding the manual flag information. * ``pd.DataFrame``, ``DictOfSeries``: Need to provide a ``pd.Series`` with column name `field`. * ``list``, ``np.ndarray``: Only supported with `method` value `` plain `` and `mformat` value `` mflag ``">
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_3">
                  <param argument="mdata" type="text" label="mdata" help="Determines which values or intervals will be flagged. Supported input types:  * ``pd.Series``: Needs a datetime index and values of type:  - datetime, for `method` values `` right-closed ``, `` left-closed ``, `` closed `` - or any scalar, for `method` values `` plain ``, `` ontime ``  * ``str``: Variable holding the manual flag information. * ``pd.DataFrame``, ``DictOfSeries``: Need to provide a ``pd.Series`` with column name `field`. * ``list``, ``np.ndarray``: Only supported with `method` value `` plain `` and `mformat` value `` mflag ``">
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_4">
                  <param argument="mdata" type="text" label="mdata" help="Determines which values or intervals will be flagged. Supported input types:  * ``pd.Series``: Needs a datetime index and values of type:  - datetime, for `method` values `` right-closed ``, `` left-closed ``, `` closed `` - or any scalar, for `method` values `` plain ``, `` ontime ``  * ``str``: Variable holding the manual flag information. * ``pd.DataFrame``, ``DictOfSeries``: Need to provide a ``pd.Series`` with column name `field`. * ``list``, ``np.ndarray``: Only supported with `method` value `` plain `` and `mformat` value `` mflag ``">
                    <validator type="empty_field"/>
                  </param>
                </when>
              </conditional>
              <param argument="method" type="select" value="left-open" optional="true" label="method" help="Defines how `mdata` is projected to data:  * `` plain ``: `mdata` must have the same length as `field`, flags are set, where the values in `mdata` equal `mflag`. * `` ontime ``: Expects datetime indexed `mdata` (types ``pd.Series``, ``pd.DataFrame``, ``DictOfSeries``). Flags are set, where the values in `mdata` equal `mflag` and the indices of `field` and `mdata` match. * `` right-open ``: Expects datetime indexed `mdata`, which will be interpreted as a number of time intervals ``t_1, t_2``. Flags are set to all timestamps ``t`` of `field` with ``t_1  = t   t_2``. * `` left-open ``: like `` right-open ``, but the interval covers all ``t`` with ``t_1   t  = t_2``. * `` closed ``: like `` right-open ``, but the interval now covers all ``t`` with ``t_1  = t  = t_2``">
                <option value="left-open">left-open</option>
                <option value="right-open">right-open</option>
                <option value="closed">closed</option>
                <option value="plain">plain</option>
                <option value="ontime">ontime</option>
              </param>
              <param argument="mformat" type="select" value="start-end" optional="true" label="mformat" help="Controls the interval definition in `mdata` (see examples):  * `` start-end ``: expects datetime indexed `mdata` (types ``pd.Series``, ``pd.DataFrame``, ``DictOfSeries``) with values of type datetime. Each index-value pair is interpreted as an interval to flag, the index defines the left bound, the respective value the right bound. * `` mflag ``:  - `mdata` of type ``pd.Series``, ``pd.DataFrame``, ``DictOfSeries``: Two successive index values ``i_1, i_2`` will be interpreted as an interval ``t_1, t_2`` to flag, if the value of ``t_1`` equals `mflag` - `mdata` of type ``list``, ``np.ndarray``: Flags all `field` where `mdata` euqals `mflag`">
                <option value="start-end">start-end</option>
                <option value="mflag">mflag</option>
              </param>
              <param argument="mflag" type="text" value="1" optional="true" label="mflag" help="Value in `mdata` indicating that a flag should be set at the respective position, timestamp or interval. Ignored if `mformat` is set to `` start-end ``"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagUnflagged">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="forceFlags">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help=""/>
            </when>
            <when value="orGroup">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param name="group" type="data" optional="true" label="group" help="A collection of ``SaQC`` objects. Flag checks are performed on all ``SaQC`` objects based on the variables specified in `field`. Whenever any of monitored variables is flagged, the associated timestamps will receive a flag" format="csv" multiple="true"/>
              <param argument="target" type="data_column" optional="true" label="target" help="`SaQCFields` | `newSaQCFields` , optional Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="propagateFlags">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="int or str Size of the repetition window. An integer defines the exact number of periods to propagate, while a string is interpreted as a time offset">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">(Integer &gt; 0)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" label="window" help="int or str Size of the repetition window. An integer defines the exact number of periods to propagate, while a string is interpreted as a time offset (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" label="window" help="int or str Size of the repetition window. An integer defines the exact number of periods to propagate, while a string is interpreted as a time offset" min="0"/>
                </when>
              </conditional>
              <param argument="method" type="select" value="ffill" optional="true" label="method" help="{ ffill ,  bfill } Direction of propagation: * ``ffill`` — propagate flag to subsequent values * ``bfill`` — propagate flag to preceding values">
                <option value="ffill">ffill</option>
                <option value="bfill">bfill</option>
              </param>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
              <param argument="dfilter" type="float" value="-inf" optional="true" label="dfilter" help="`Any`, optional Defines which observations will be masked based on the already existing flags. Any data point with a flag equal or worse to this threshold will be passed as ``NaN`` to the function. Defaults to the ``DFILTER_ALL`` value of the translation scheme"/>
            </when>
            <when value="transferFlags">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="target" type="data_column" optional="true" label="target" help="`SaQCFields` | `newSaQCFields` , optional Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="squeeze" type="boolean" label="squeeze" help="bool If True, compress the history into a single column, losing function-specific flag information" checked="false" truevalue="squeeze" falsevalue=""/>
              <param argument="overwrite" type="boolean" label="overwrite" help="bool If True, existing flags in the target field are overwritten" checked="false" truevalue="overwrite" falsevalue=""/>
            </when>
          </conditional>
        </when>
        <when value="generic">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="flagGeneric">flagGeneric: Flag data based on a given function</option>
              <option value="processGeneric">processGeneric: Generate/process data with user defined functions</option>
            </param>
            <when value="flagGeneric">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="func" type="text" label="func" help="Function to call. The function needs to accept the same number of arguments (of type pandas.Series) as variables given in ``field`` and return an iterable of array-like objects of data type ``bool`` with the same length as ``target``">
                <validator type="regex" message="Must provide a valid function name (e.g., 'mean') or Python expression."><![CDATA[^(?!\s*$).+]]></validator>
              </param>
              <param argument="target" type="data_column" optional="true" label="target" help="`SaQCFields` | `newSaQCFields` , optional Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="processGeneric">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="func" type="text" label="func" help="Function to call on the variables given in ``field``. The return value will be written to ``target`` or ``field`` if the former is not given. This implies, that the function needs to accept the same number of arguments (of type pandas.Series) as variables given in ``field`` and should return an iterable of array-like objects with the same number of elements as given in ``target`` (or ``field`` if ``target`` is not specified)">
                <validator type="regex" message="Must provide a valid function name (e.g., 'mean') or Python expression."><![CDATA[^(?!\s*$).+]]></validator>
              </param>
              <param argument="target" type="data_column" optional="true" label="target" help="`SaQCFields` | `newSaQCFields` , optional Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="dfilter" type="float" value="-inf" optional="true" label="dfilter" help="`Any`, optional Defines which observations will be masked based on the already existing flags. Any data point with a flag equal or worse to this threshold will be passed as ``NaN`` to the function. Defaults to the ``DFILTER_ALL`` value of the translation scheme"/>
            </when>
          </conditional>
        </when>
        <when value="interpolation">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="align">align: Convert a time series to a specified frequency, interpolating values</option>
              <option value="interpolateByRolling">interpolateByRolling: Replace NaN by the aggregation result of the surrounding window</option>
            </param>
            <when value="align">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="freq_cond" label="freq">
                <param name="freq_selector" type="select" label="Choose type for 'freq'" help="str or int Target frequency (e.g.,  1H ,  15min , 60)">
                  <option value="type_0">Frequency String</option>
                  <option value="type_1">Integer</option>
                </param>
                <when value="type_0">
                  <param argument="freq" type="text" label="freq" help="str or int Target frequency (e.g.,  1H ,  15min , 60) (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="freq" type="integer" label="freq" help="str or int Target frequency (e.g.,  1H ,  15min , 60)"/>
                </when>
              </conditional>
              <param argument="method" type="text" value="time" label="method" help="str Interpolation technique to use. Supported values include:  * ``'nshift'``: Shift grid points to the nearest time stamp within +/- 0.5 * ``freq``. * ``'bshift'``: Shift grid points to the first succeeding time stamp. * ``'fshift'``: Shift grid points to the last preceding time stamp. * ``'linear'``, ``'time'``, ``'index'``, ``'values'``: Use numerical values of the index. (Note: internally mapped to ``'mshift'``.) * ``'pad'``: Fill NaNs using existing values (same as ``'fshift'``). * ``'spline'``, ``'polynomial'``: Passed to ``scipy.interpolate.interp1d``. Requires specifying ``order``. * ``'nearest'``, ``'zero'``, ``'slinear'``, ``'quadratic'``, ``'cubic'``, ``'barycentric'``: Passed to ``scipy.interpolate.interp1d``. * ``'krogh'``, ``'pchip'``, ``'akima'``, ``'cubicspline'``: Wrappers around SciPy interpolation methods. * ``'from_derivatives'``: Uses ``scipy.interpolate.BPoly.from_derivatives``"/>
              <param argument="order" type="integer" value="2" optional="true" label="order" help="int Order of the interpolation method. Used only by methods that support it (e.g., polynomial, spline). Ignored otherwise" min="0"/>
              <param argument="overwrite" type="boolean" label="overwrite" help="bool If ``True``, existing flags will be cleared" checked="false" truevalue="overwrite" falsevalue=""/>
            </when>
            <when value="interpolateByRolling">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="The size of the window, the aggregation is computed from. An integer define the number of periods to be used, a string is interpreted as an offset. ( see `pandas.rolling` for more information). Integer windows may result in screwed aggregations if called on none-harmonized or irregular data">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">(Integer &gt; 0)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" label="window" help="The size of the window, the aggregation is computed from. An integer define the number of periods to be used, a string is interpreted as an offset. ( see `pandas.rolling` for more information). Integer windows may result in screwed aggregations if called on none-harmonized or irregular data (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" label="window" help="The size of the window, the aggregation is computed from. An integer define the number of periods to be used, a string is interpreted as an offset. ( see `pandas.rolling` for more information). Integer windows may result in screwed aggregations if called on none-harmonized or irregular data" min="0"/>
                </when>
              </conditional>
              <param argument="center" type="boolean" label="center" help="Center the window around the value. Can only be used with integer windows, otherwise it is silently ignored" checked="false" truevalue="center" falsevalue=""/>
              <param argument="min_periods" type="integer" value="0" optional="true" label="min_periods" help="Minimum number of valid (not np.nan) values that have to be available in a window for its aggregation to be computed" min="0"/>
              <param argument="flag" type="float" value="-inf" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
          </conditional>
        </when>
        <when value="noise">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="flagByScatterLowpass">flagByScatterLowpass: Flag anomalous data chunks based on scatter statistics</option>
            </param>
            <when value="flagByScatterLowpass">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="str or pandas.Timedelta Size of the main chunk (time-based)">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">Pd.Timedelta</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" label="window" help="str or pandas.Timedelta Size of the main chunk (time-based) (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="text" label="window" help="str or pandas.Timedelta Size of the main chunk (time-based)">
                    <validator type="regex" message="Please enter a valid Timedelta string (e.g., '30min', '2H', '1D')."><![CDATA[^\s*-?\d+(\.\d+)?\s*(D|H|T|S|L|U|N|days?|hours?|minutes?|seconds?|weeks?|milliseconds?|microseconds?|nanoseconds?)\s*$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
              </conditional>
              <param argument="thresh" type="float" label="thresh" help="float Threshold, the statistic of the main chunk is checked against. ``func(chunk)   thresh``" min="0"/>
              <param argument="func" type="select" value="std" optional="true" label="func" help="{ std ,  var ,  mad } or Callable[[np.ndarray, pd.Series], float] Function to compute deviation for each chunk: * `` std `` — standard deviation * `` var `` — variance * `` mad `` — median absolute deviation * Callable — custom function mapping 1D arrays to scalars">
                <option value="std">std</option>
                <option value="var">var</option>
                <option value="mad">mad</option>
              </param>
              <conditional name="sub_window_cond" label="sub_window">
                <param name="sub_window_selector" type="select" label="Choose type for 'sub_window'" help="str or pandas.Timedelta, optional Size of sub-chunks for secondary testing">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">Pd.Timedelta</option>
                </param>
                <when value="type_0">
                  <param argument="sub_window" type="text" optional="true" label="sub_window" help="str or pandas.Timedelta, optional Size of sub-chunks for secondary testing (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="sub_window" type="text" label="sub_window" help="str or pandas.Timedelta, optional Size of sub-chunks for secondary testing">
                    <validator type="regex" message="Please enter a valid Timedelta string (e.g., '30min', '2H', '1D')."><![CDATA[^\s*-?\d+(\.\d+)?\s*(D|H|T|S|L|U|N|days?|hours?|minutes?|seconds?|weeks?|milliseconds?|microseconds?|nanoseconds?)\s*$]]></validator>
                  </param>
                </when>
              </conditional>
              <param argument="sub_thresh" type="float" optional="true" label="sub_thresh" help="float, optional Threshold, the statistic of the main chunk is checked against. ``func(sub_chunk)   sub_thresh``" min="0"/>
              <param argument="min_periods" type="integer" optional="true" label="min_periods" help="int, optional Minimum number of values required in a chunk to perform the test. Ignored if ``window`` is an integer" min="0"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
          </conditional>
        </when>
        <when value="outliers">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="flagByGrubbs">flagByGrubbs: Flag outliers using the Grubbs algorithm</option>
              <option value="flagByStray">flagByStray: Flag outliers in 1-dimensional (score) data using the STRAY Algorithm</option>
              <option value="flagLOF">flagLOF: Flag values where the Local Outlier Factor (LOF) exceeds cutoff</option>
              <option value="flagMAD">flagMAD: Flag outliers using the modified Z-score outlier detection method</option>
              <option value="flagMVScores">flagMVScores: The algorithm implements a 3-step outlier detection procedure for</option>
              <option value="flagOffset">flagOffset: Flag offsetting value courses</option>
              <option value="flagRaise">flagRaise: The function flags raises and drops in value courses, that exceed a certain threshold within a certain timespan</option>
              <option value="flagRange">flagRange: Flag values outside the closed interval [`min`, `max`]</option>
              <option value="flagUniLOF">flagUniLOF: Flag anomalous values using the *Univariate Local Outlier Factor (UniLOF)* method</option>
              <option value="flagZScore">flagZScore: Uses standard score cutoffs to detect outliers. (For example,  *3*-sigma rule .)</option>
            </param>
            <when value="flagByGrubbs">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="Size of the testing window. If an integer, the fixed number of observations used for each window. If an offset string the time period of each window">
                  <option value="type_0">Frequency String</option>
                  <option value="type_1">(Integer &gt;= 0)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" label="window" help="Size of the testing window. If an integer, the fixed number of observations used for each window. If an offset string the time period of each window (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" label="window" help="Size of the testing window. If an integer, the fixed number of observations used for each window. If an offset string the time period of each window" min="0"/>
                </when>
              </conditional>
              <param argument="alpha" type="float" value="0.05" optional="true" label="alpha" help="Level of significance, the grubbs test is to be performed at. Must be between 0 and 1" min="0" max="1"/>
              <param argument="min_periods" type="integer" value="8" optional="true" label="min_periods" help="Minimum number of values needed in a `window` in order to perform the grubs test. Ignored if `window` is an integer" min="1"/>
              <param argument="pedantic" type="boolean" label="pedantic" help="If ``True``, every value gets checked twice. First in the initial rolling `window` and second in a rolling window that is lagging by `window` / 2. Recommended to avoid false positives at the window edges. Ignored if `window` is an offset string" checked="false" truevalue="pedantic" falsevalue=""/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagByStray">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="Determines the segmentation of the data into partitions, the kNN algorithm is applied onto individually.  * ``None``: Apply Scoring on whole data set at once * ``int``: Apply scoring on successive data chunks of periods with the given length. Must be greater than 0. * offset String : Apply scoring on successive partitions of temporal extension matching the passed offset string">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">(Integer &gt;= 1)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" optional="true" label="window" help="Determines the segmentation of the data into partitions, the kNN algorithm is applied onto individually.  * ``None``: Apply Scoring on whole data set at once * ``int``: Apply scoring on successive data chunks of periods with the given length. Must be greater than 0. * offset String : Apply scoring on successive partitions of temporal extension matching the passed offset string (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" optional="true" label="window" help="Determines the segmentation of the data into partitions, the kNN algorithm is applied onto individually.  * ``None``: Apply Scoring on whole data set at once * ``int``: Apply scoring on successive data chunks of periods with the given length. Must be greater than 0. * offset String : Apply scoring on successive partitions of temporal extension matching the passed offset string" min="1"/>
                </when>
              </conditional>
              <param argument="min_periods" type="integer" value="11" optional="true" label="min_periods" help="Minimum number of periods per partition that have to be present for a valid outlier detection to be made in this partition" min="1"/>
              <param argument="iter_start" type="float" value="0.5" optional="true" label="iter_start" help="Float in ``[0, 1]`` that determines which percentage of data is considered  normal . ``0.5`` results in the stray algorithm to search only the upper 50% of the scores for the cut off point. (See reference section for more information)" min="0" max="1"/>
              <param argument="alpha" type="float" value="0.05" optional="true" label="alpha" help="Level of significance by which it is tested, if a score might be drawn from another distribution than the majority of the data" min="0" max="1"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagLOF">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="n" type="integer" value="20" optional="true" label="n" help="Number of neighbors to be included into the LOF calculation. Defaults to ``20``, which is a value found to be suitable in the literature.  * `n` determines the  locality  of an observation (its `n` nearest neighbors) and sets the upper limit to the number of values in outlier clusters (i.e. consecutive outliers). Outlier clusters of size greater than `n`/2 may not be detected reliably. * The larger `n`, the lesser the algorithm's sensitivity to local outliers and small or singleton outliers points. Higher values greatly increase numerical costs" min="0"/>
              <conditional name="thresh_cond" label="thresh">
                <param name="thresh_selector" type="select" label="Choose type for 'thresh'" help="The threshold for flagging the calculated LOF. A LOF of around ``1`` is considered normal and most likely corresponds to inlier points.  * The  automatic  threshing introduced with the publication of the algorithm defaults to ``1.5``. * In this implementation, `thresh` defaults (``'auto'``) to flagging the scores with a modified 3-sigma rule">
                  <option value="type_0">Selection</option>
                  <option value="type_1">(Float &gt;= 1)</option>
                </param>
                <when value="type_0">
                  <param argument="thresh" type="select" optional="true" label="thresh" help="The threshold for flagging the calculated LOF. A LOF of around ``1`` is considered normal and most likely corresponds to inlier points.  * The  automatic  threshing introduced with the publication of the algorithm defaults to ``1.5``. * In this implementation, `thresh` defaults (``'auto'``) to flagging the scores with a modified 3-sigma rule">
                    <option value="auto">auto</option>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="thresh" type="float" optional="true" label="thresh" help="The threshold for flagging the calculated LOF. A LOF of around ``1`` is considered normal and most likely corresponds to inlier points.  * The  automatic  threshing introduced with the publication of the algorithm defaults to ``1.5``. * In this implementation, `thresh` defaults (``'auto'``) to flagging the scores with a modified 3-sigma rule" min="1"/>
                </when>
              </conditional>
              <param argument="algorithm" type="select" value="ball_tree" optional="true" label="algorithm" help="Algorithm used for calculating the `n`-nearest neighbors">
                <option value="ball_tree">ball_tree</option>
                <option value="kd_tree">kd_tree</option>
                <option value="brute">brute</option>
                <option value="auto">auto</option>
              </param>
              <param argument="p" type="integer" value="1" optional="true" label="p" help="Degree of the metric ( Minkowski ), according to which the distance to neighbors is determined. Most important values are:  * ``1`` - Manhattan Metric * ``2`` - Euclidian Metric" min="0"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagMAD">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="Size of the window. Either given as an Offset String, denoting the window's temporal extension or as an integer, denoting the window's number of periods. ``NaN`` also count as periods. If ``None``, all data points share the same scoring window, which than equals the whole data">
                  <option value="type_0">Frequency String</option>
                  <option value="type_1">(Integer &gt;= 0)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" optional="true" label="window" help="Size of the window. Either given as an Offset String, denoting the window's temporal extension or as an integer, denoting the window's number of periods. ``NaN`` also count as periods. If ``None``, all data points share the same scoring window, which than equals the whole data (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" optional="true" label="window" help="Size of the window. Either given as an Offset String, denoting the window's temporal extension or as an integer, denoting the window's number of periods. ``NaN`` also count as periods. If ``None``, all data points share the same scoring window, which than equals the whole data" min="0"/>
                </when>
              </conditional>
              <param argument="z" type="float" value="3.5" optional="true" label="z" help="The value the Z-score is tested against. Defaulting to ``3.5`` (Recommendation of [1])" min="0"/>
              <param argument="min_residuals" type="integer" optional="true" label="min_residuals" help="" min="0"/>
              <param argument="min_periods" type="integer" optional="true" label="min_periods" help="Minimum number of valid meassurements in a scoring window, to consider the resulting score valid" min="0"/>
              <param argument="center" type="boolean" label="center" help="Weather or not to center the target value in the scoring window. If ``False``, the target value is the last value in the window" checked="false" truevalue="center" falsevalue=""/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagMVScores">
              <param argument="field" type="data_column" label="field" help="List of variables names to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="trafo" type="text" label="trafo" help="Transformation to be applied onto every column before scoring. For more fine-grained control, the data could also be transformed before :py:meth:`~saqc.SaQC.flagMVScores` is called"/>
              <param argument="alpha" type="float" value="0.05" optional="true" label="alpha" help="Level of significance by which it is tested, if an observations score might be drawn from another distribution than the majority of the data" min="0" max="1"/>
              <param argument="n" type="integer" value="10" optional="true" label="n" help="Number of neighbors included in the scoring process for every datapoint" min="1"/>
              <param argument="iter_start" type="float" value="0.5" optional="true" label="iter_start" help="Value in ``[0,1]`` that determines which percentage of data is considered  normal . 0.5 results in the threshing algorithm to search only the upper 50% of the scores for the cut-off point. (See reference section for more information)" min="0" max="1"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="Only effective if `threshing` is set to ``'stray'``. Determines the size of the data partitions, the data is decomposed into. Each partition is checked seperately for outliers. Either given as an Offset String, denoting the windows temporal extension or as an integer, denoting the windows number of periods. ``NaN`` also count as periods. If ``None``, all data points share the same scoring window, which than equals the whole data">
                  <option value="type_0">(Integer &gt;= 1)</option>
                  <option value="type_1">Offset String</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="integer" optional="true" label="window" help="Only effective if `threshing` is set to ``'stray'``. Determines the size of the data partitions, the data is decomposed into. Each partition is checked seperately for outliers. Either given as an Offset String, denoting the windows temporal extension or as an integer, denoting the windows number of periods. ``NaN`` also count as periods. If ``None``, all data points share the same scoring window, which than equals the whole data" min="1"/>
                </when>
                <when value="type_1">
                  <param argument="window" type="text" optional="true" label="window" help="Only effective if `threshing` is set to ``'stray'``. Determines the size of the data partitions, the data is decomposed into. Each partition is checked seperately for outliers. Either given as an Offset String, denoting the windows temporal extension or as an integer, denoting the windows number of periods. ``NaN`` also count as periods. If ``None``, all data points share the same scoring window, which than equals the whole data (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
              </conditional>
              <param argument="min_periods" type="integer" value="11" optional="true" label="min_periods" help="Only effective if `threshing` is set to ``'stray'`` and `partition` is an integer. Minimum number of periods per `partition` that have to be present for a valid outlier detection to be made in this partition" min="1"/>
              <param argument="stray_range" type="text" optional="true" label="stray_range" help="If not ``None``, it is tried to reduce the stray result onto single outlier components of the input `field`. The offset string denotes the range of the temporal surrounding to include into the MAD testing while trying to reduce flags (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
              </param>
              <param argument="drop_flagged" type="boolean" label="drop_flagged" help="Only effective when `stray_range` is not ``None``. Whether or not to drop flagged values from the temporal surroundings" checked="false" truevalue="drop_flagged" falsevalue=""/>
              <param argument="thresh" type="float" value="3.5" optional="true" label="thresh" help="Only effective when `stray_range` is not ``None``. The 'critical' value, controlling wheather the MAD score is considered referring to an outlier or not. Higher values result in less rigid flagging. The default value is widely considered apropriate in the literature" min="0"/>
              <param argument="min_periods_r" type="integer" value="1" optional="true" label="min_periods_r" help="Only effective when `stray_range` is not ``None``. Minimum number of measurements necessary in an interval to actually perform the reduction step" min="1"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagOffset">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="window" type="text" label="window" help="str Maximum temporal length allowed for an offset sequence to trigger flagging (condition 5). Integer-defined windows are only allowed for regularly sampled timestamps (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="tolerance" type="float" optional="true" label="tolerance" help="float Maximum allowed difference between the value preceding and succeeding an offset sequence to trigger flagging (condition 4)" min="0"/>
              <param argument="thresh" type="float" optional="true" label="thresh" help="float or None Minimum absolute difference between a value and its successors to consider the successors a possible anomalous offset sequence (condition 1). If None, this condition is ignored" min="0"/>
              <conditional name="thresh_relative_cond" label="thresh_relative">
                <param name="thresh_relative_selector" type="select" label="Choose type for 'thresh_relative'" help="float or None Minimum relative change between a value and its successors to consider the successors a possible anomalous offset sequence (conditions 2 and 3). If None, this condition is ignored. The parameter constrains the detection to either upwards (positive value passed) or downwards (negative values passed) offsets. To assign detection of offsets bigger than `a`, positive as well as negative, pass the tuple `(a,-a)`. Differing positive and negative threshold values are possible as well. See condition (2). If ``None``, condition (2) is not tested">
                  <option value="type_0">Multiple values (Tuple)</option>
                  <option value="type_1">Float</option>
                </param>
                <when value="type_0">
                  <repeat name="thresh_relative" title="thresh_relative" help="float or None Minimum relative change between a value and its successors to consider the successors a possible anomalous offset sequence (conditions 2 and 3). If None, this condition is ignored. The parameter constrains the detection to either upwards (positive value passed) or downwards (negative values passed) offsets. To assign detection of offsets bigger than `a`, positive as well as negative, pass the tuple `(a,-a)`. Differing positive and negative threshold values are possible as well. See condition (2). If ``None``, condition (2) is not tested">
                    <param argument="thresh_relative_pos0" type="text" label="thresh_relative_pos0" help="First element (index 0) of the thresh_relative tuple."/>
                    <param argument="thresh_relative_pos1" type="text" label="thresh_relative_pos1" help="Second element (index 1) of the thresh_relative tuple."/>
                  </repeat>
                </when>
                <when value="type_1">
                  <param argument="thresh_relative" type="float" optional="true" label="thresh_relative" help="float or None Minimum relative change between a value and its successors to consider the successors a possible anomalous offset sequence (conditions 2 and 3). If None, this condition is ignored. The parameter constrains the detection to either upwards (positive value passed) or downwards (negative values passed) offsets. To assign detection of offsets bigger than `a`, positive as well as negative, pass the tuple `(a,-a)`. Differing positive and negative threshold values are possible as well. See condition (2). If ``None``, condition (2) is not tested"/>
                </when>
              </conditional>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagRaise">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="thresh" type="float" label="thresh" help="The threshold, for the total rise (`thresh` ``  0``), or total drop (`thresh` ``  0``), value courses must not exceed within a timespan of length `raise_window`"/>
              <param argument="raise_window" type="text" label="raise_window" help="An offset string, determining the timespan, the rise/drop thresholding refers to. Window is inclusively defined (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="freq" type="text" label="freq" help="An offset string, determining the frequency, the timeseries to flag is supposed to be sampled at. The window is inclusively defined (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                <validator type="empty_field"/>
              </param>
              <param argument="average_window" type="text" optional="true" label="average_window" help="See condition (2) of the description given in the Notes. Window is inclusively defined, defaults to 1.5 times the size of `raise_window` (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
              </param>
              <param argument="raise_factor" type="float" value="2.0" optional="true" label="raise_factor" help="See condition (2)" min="1"/>
              <param argument="slope" type="float" optional="true" label="slope" help="See condition (3)" min="0"/>
              <param argument="weight" type="float" value="0.8" optional="true" label="weight" help="See condition (3)" min="0"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagRange">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="min" type="float" value="-inf" optional="true" label="min" help="float Lower bound for valid data"/>
              <param argument="max" type="float" value="inf" optional="true" label="max" help="float Upper bound for valid data"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagUniLOF">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="n" type="integer" value="20" optional="true" label="n" help="int Number of samples to include in the LOF neighborhood (the ``n`` nearest neighbors)" min="0"/>
              <conditional name="thresh_cond" label="thresh">
                <param name="thresh_selector" type="select" label="Choose type for 'thresh'" help="{'auto', float}, optional Outlier-factor cutoff. Values with LOF scores greater than this threshold are flagged">
                  <option value="type_0">Selection</option>
                  <option value="type_1">(Float &gt;= 0)</option>
                </param>
                <when value="type_0">
                  <param argument="thresh" type="select" optional="true" label="thresh" help="{'auto', float}, optional Outlier-factor cutoff. Values with LOF scores greater than this threshold are flagged">
                    <option value="auto">auto</option>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="thresh" type="float" optional="true" label="thresh" help="{'auto', float}, optional Outlier-factor cutoff. Values with LOF scores greater than this threshold are flagged" min="0"/>
                </when>
              </conditional>
              <param argument="probability" type="float" optional="true" label="probability" help="float, optional Outlier-probability cutoff. Values with probabilities greater than this threshold are flagged" min="0" max="1"/>
              <conditional name="corruption_cond" label="corruption">
                <param name="corruption_selector" type="select" label="Choose type for 'corruption'" help="float or int, optional Portion of data assumed to be anomalous, either as a fraction in ``[0, 1]`` or as an integer specifying the number of anomalous samples">
                  <option value="type_0">Float[0, 1]</option>
                  <option value="type_1">(Integer &gt; 0)</option>
                </param>
                <when value="type_0">
                  <param argument="corruption" type="float" optional="true" label="corruption" help="float or int, optional Portion of data assumed to be anomalous, either as a fraction in ``[0, 1]`` or as an integer specifying the number of anomalous samples" min="0" max="1"/>
                </when>
                <when value="type_1">
                  <param argument="corruption" type="integer" optional="true" label="corruption" help="float or int, optional Portion of data assumed to be anomalous, either as a fraction in ``[0, 1]`` or as an integer specifying the number of anomalous samples" min="0"/>
                </when>
              </conditional>
              <param argument="algorithm" type="select" value="ball_tree" optional="true" label="algorithm" help="{'ball_tree', 'kd_tree', 'brute', 'auto'} Nearest-neighbor algorithm used for LOF">
                <option value="ball_tree">ball_tree</option>
                <option value="kd_tree">kd_tree</option>
                <option value="brute">brute</option>
                <option value="auto">auto</option>
              </param>
              <param argument="p" type="integer" value="1" optional="true" label="p" help="int Degree of the Minkowski metric used for neighbor distances (e.g., ``1`` Manhattan, ``2`` Euclidean)" min="0"/>
              <conditional name="density_cond" label="density">
                <param name="density_selector" type="select" label="Choose type for 'density'" help="{'auto', float} How to derive temporal density. ``'auto'`` uses the median absolute step size; a ``float`` sets a fixed increment">
                  <option value="type_0">Selection</option>
                  <option value="type_1">(Float &gt; 0)</option>
                </param>
                <when value="type_0">
                  <param argument="density" type="select" optional="true" label="density" help="{'auto', float} How to derive temporal density. ``'auto'`` uses the median absolute step size; a ``float`` sets a fixed increment">
                    <option value="auto">auto</option>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="density" type="float" optional="true" label="density" help="{'auto', float} How to derive temporal density. ``'auto'`` uses the median absolute step size; a ``float`` sets a fixed increment" min="0"/>
                </when>
              </conditional>
              <param argument="fill_na" type="boolean" label="fill_na" help="bool If ``True``, fill NaNs by linear interpolation before LOF calculation" checked="false" truevalue="fill_na" falsevalue=""/>
              <param argument="slope_correct" type="boolean" label="slope_correct" help="bool If ``True``, suppress flagging of groups of points, that seem to correspond to steep value slopes rather than to actual outliers" checked="false" truevalue="slope_correct" falsevalue=""/>
              <param argument="min_offset" type="float" optional="true" label="min_offset" help="float, optional Minimum jump in values before and after an outlier cluster for it to be flagged" min="0"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagZScore">
              <param argument="field" type="data_column" label="field" help="List of variables names to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="method" type="select" value="standard" optional="true" label="method" help="{ standard ,  modified } Which scoring method to use:  * `` standard `` — mean as expectation, standard deviation as scaling factor. * `` modified `` — median as expectation, median absolute deviation (MAD) as scaling factor">
                <option value="standard">standard</option>
                <option value="modified">modified</option>
              </param>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="int or str, optional Size of the scoring window. Either an integer (number of periods) or an offset string (time span). If ``None`` (default), all data share a single window">
                  <option value="type_0">Frequency String</option>
                  <option value="type_1">(Integer &gt;= 0)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" optional="true" label="window" help="int or str, optional Size of the scoring window. Either an integer (number of periods) or an offset string (time span). If ``None`` (default), all data share a single window (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" optional="true" label="window" help="int or str, optional Size of the scoring window. Either an integer (number of periods) or an offset string (time span). If ``None`` (default), all data share a single window" min="0"/>
                </when>
              </conditional>
              <param argument="thresh" type="float" value="3" optional="true" label="thresh" help="float Cutoff value. Points with absolute Z-scores larger than this threshold are flagged" min="0"/>
              <param argument="min_residuals" type="float" optional="true" label="min_residuals" help="float, optional Minimum absolute distance a value must be apart from its context windows expectation, in order for the Z scoring test to be applied" min="0"/>
              <param argument="min_periods" type="integer" optional="true" label="min_periods" help="int, optional Minimum number of valid observations that is required to be contained in a values context window, in order for the Z scoring test to be applied" min="0"/>
              <param argument="center" type="boolean" label="center" help="bool If ``True`` (default), the tested value is centered in its context window; otherwise, it is the window’s last value" checked="false" truevalue="center" falsevalue=""/>
              <param argument="axis" type="integer" value="0" optional="true" label="axis" help="{0, 1} Axis along which to compute scores:  * ``0`` (default) — compute along the time axis only (separate windows for all fields). * ``1`` — compute along time and data axis (windows are 2 dimensional and span over all fields)" min="0" max="1"/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
          </conditional>
        </when>
        <when value="pattern">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="flagPatternByDTW">flagPatternByDTW: Pattern Recognition via Dynamic Time Warping</option>
              <option value="flagPlateau">flagPlateau: Flag anomalous value plateaus</option>
            </param>
            <when value="flagPatternByDTW">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="reference" type="text" label="reference" help="The name in `data` which holds the pattern. The pattern must not have NaNs, have a datetime index and must not be empty">
                <validator type="empty_field"/>
              </param>
              <param argument="max_distance" type="float" value="0.0" optional="true" label="max_distance" help="Maximum dtw-distance between chunk and pattern, if the distance is lower than ``max_distance`` the data gets flagged. With default, ``0.0``, only exact matches are flagged" min="0"/>
              <param argument="normalize" type="boolean" label="normalize" help="If `False`, return unmodified distances. If `True`, normalize distances by the number of observations of the reference. This helps to make it easier to find a good cutoff threshold for further processing. The distances then refer to the mean distance per datapoint, expressed in the datas units" checked="false" truevalue="normalize" falsevalue=""/>
              <param argument="plot" type="boolean" label="plot" help="Show a calibration plot, which can be quite helpful to find the right threshold for `max_distance`. It works best with `normalize=True`. Do not use in automatic setups / pipelines. The plot show three lines:  - data: the data the function was called on - distances: the calculated distances by the algorithm - indicator: have to distinct levels: `0` and the value of `max_distance`. If `max_distance` is `0.0` it defaults to `1`. Everywhere where the indicator is not `0` the data will be flagged" checked="false" truevalue="plot" falsevalue=""/>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
            <when value="flagPlateau">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="min_length_cond" label="min_length">
                <param name="min_length_selector" type="select" label="Choose type for 'min_length'" help="int or str Minimum temporal extension of a value course to qualify as a plateau">
                  <option value="type_0">(Integer &gt; 0)</option>
                  <option value="type_1">Offset String</option>
                </param>
                <when value="type_0">
                  <param argument="min_length" type="integer" label="min_length" help="int or str Minimum temporal extension of a value course to qualify as a plateau" min="0"/>
                </when>
                <when value="type_1">
                  <param argument="min_length" type="text" label="min_length" help="int or str Minimum temporal extension of a value course to qualify as a plateau (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
              </conditional>
              <conditional name="max_length_cond" label="max_length">
                <param name="max_length_selector" type="select" label="Choose type for 'max_length'" help="int, str, or None Maximum temporal extension of a value course to qualify as a plateau (upper detection limit). If None, a detection limit based on the data length is used">
                  <option value="type_0">(Integer &gt; 0)</option>
                  <option value="type_1">Offset String</option>
                </param>
                <when value="type_0">
                  <param argument="max_length" type="integer" optional="true" label="max_length" help="int, str, or None Maximum temporal extension of a value course to qualify as a plateau (upper detection limit). If None, a detection limit based on the data length is used" min="0"/>
                </when>
                <when value="type_1">
                  <param argument="max_length" type="text" optional="true" label="max_length" help="int, str, or None Maximum temporal extension of a value course to qualify as a plateau (upper detection limit). If None, a detection limit based on the data length is used (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
              </conditional>
              <param argument="min_jump" type="float" optional="true" label="min_jump" help="float or None Minimum difference a plateau must have from directly preceding and succeeding periods. If None, the minimum jump threshold is derived automatically from the median of local absolute differences in the vicinity of potential anomalies" min="0"/>
              <conditional name="granularity_cond" label="granularity">
                <param name="granularity_selector" type="select" label="Choose type for 'granularity'" help="int, str, or None Precision of the search. Smaller values increase precision but also computational cost. If None, defaults to 5">
                  <option value="type_0">(Integer &gt; 0)</option>
                  <option value="type_1">Offset String</option>
                </param>
                <when value="type_0">
                  <param argument="granularity" type="integer" optional="true" label="granularity" help="int, str, or None Precision of the search. Smaller values increase precision but also computational cost. If None, defaults to 5" min="0"/>
                </when>
                <when value="type_1">
                  <param argument="granularity" type="text" optional="true" label="granularity" help="int, str, or None Precision of the search. Smaller values increase precision but also computational cost. If None, defaults to 5 (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
              </conditional>
              <param argument="flag" type="float" value="255.0" optional="true" label="flag" help="`Any`, optional The flag value the function uses to mark observations. Defaults to the ``BAD`` value of the translation scheme"/>
            </when>
          </conditional>
        </when>
        <when value="resampling">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="concatFlags">concatFlags: Project flags/history of `field` to `target` and adjust to the frequeny grid</option>
              <option value="reindex">reindex: Change a variables index</option>
              <option value="resample">resample: Resample data points and flags to a regular frequency</option>
            </param>
            <when value="concatFlags">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="target" type="data_column" optional="true" label="target" help="`SaQCFields` | `newSaQCFields` Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="method" type="select" value="auto" optional="true" label="method" help="Method to project the flags of `field` to the flags to `target`:  * ``'auto'``: invert the last alignment/resampling operation (that is not already inverted) * ``'nagg'``: project a flag of `field` to all timestamps of `target` within the range +/- `freq`/2. * ``'bagg'``: project a flag of `field` to all preceeding timestamps of `target` within the range `freq` * ``'fagg'``: project a flag of `field` to all succeeding timestamps of `target` within the range `freq` * ``'interpolation'`` - project a flag of `field` to all timestamps of `target` within the range +/- `freq` * ``'sshift'`` - same as interpolation * ``'nshift'`` - project a flag of `field` to the neaerest timestamps in `target` within the range +/- `freq`/2 * ``'bshift'`` - project a flag of `field` to nearest preceeding timestamps in `target` * ``'nshift'`` - project a flag of `field` to nearest succeeding timestamps in `target` * ``'match'`` - project a flag of `field` to all identical timestamps `target`">
                <option value="fagg">fagg</option>
                <option value="bagg">bagg</option>
                <option value="nagg">nagg</option>
                <option value="fshift">fshift</option>
                <option value="bshift">bshift</option>
                <option value="nshift">nshift</option>
                <option value="sshift">sshift</option>
                <option value="mshift">mshift</option>
                <option value="match">match</option>
                <option value="auto">auto</option>
                <option value="linear">linear</option>
                <option value="pad">pad</option>
              </param>
              <param argument="invert" type="boolean" label="invert" help="If True, not the actual method is applied, but its inversion-method" checked="false" truevalue="invert" falsevalue=""/>
              <conditional name="freq_cond" label="freq">
                <param name="freq_selector" type="select" label="Choose type for 'freq'" help="Projection range. If ``None`` the sampling frequency of `field` is used">
                  <option value="type_0">Frequency String</option>
                  <option value="type_1">Pd.Timedelta</option>
                </param>
                <when value="type_0">
                  <param argument="freq" type="text" optional="true" label="freq" help="Projection range. If ``None`` the sampling frequency of `field` is used (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="freq" type="text" label="freq" help="Projection range. If ``None`` the sampling frequency of `field` is used">
                    <validator type="regex" message="Please enter a valid Timedelta string (e.g., '30min', '2H', '1D')."><![CDATA[^\s*-?\d+(\.\d+)?\s*(D|H|T|S|L|U|N|days?|hours?|minutes?|seconds?|weeks?|milliseconds?|microseconds?|nanoseconds?)\s*$]]></validator>
                  </param>
                </when>
              </conditional>
              <param argument="drop" type="boolean" label="drop" help="Remove `field` if ``True``" checked="false" truevalue="drop" falsevalue=""/>
              <param argument="squeeze" type="boolean" label="squeeze" help="Squeeze the history into a single column if ``True``, function specific flag information is lost" checked="false" truevalue="squeeze" falsevalue=""/>
              <param argument="override" type="boolean" label="override" help="Overwrite existing flags if ``True``" checked="false" truevalue="override" falsevalue=""/>
            </when>
            <when value="reindex">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="index_cond" label="index">
                <param name="index_selector" type="select" label="Choose type for 'index'" help="Determines the new index.  * If an `offset` string: new index will range from start to end of the original index of `field`, exhibting a uniform sampling rate of `idx` * If a `str` that matches a field present in the `SaQC` object, that fields index will be used as new index of `field` * If an `pd.index` object is passed, that will be the new index of `field`">
                  <option value="type_0">Frequency String</option>
                  <option value="type_1">Pd.Datetimeindex</option>
                  <option value="type_2">Text</option>
                </param>
                <when value="type_0">
                  <param argument="index" type="text" label="index" help="Determines the new index.  * If an `offset` string: new index will range from start to end of the original index of `field`, exhibting a uniform sampling rate of `idx` * If a `str` that matches a field present in the `SaQC` object, that fields index will be used as new index of `field` * If an `pd.index` object is passed, that will be the new index of `field` (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="index" type="text" label="index" help="Determines the new index.  * If an `offset` string: new index will range from start to end of the original index of `field`, exhibting a uniform sampling rate of `idx` * If a `str` that matches a field present in the `SaQC` object, that fields index will be used as new index of `field` * If an `pd.index` object is passed, that will be the new index of `field`">
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_2">
                  <param argument="index" type="text" label="index" help="Determines the new index.  * If an `offset` string: new index will range from start to end of the original index of `field`, exhibting a uniform sampling rate of `idx` * If a `str` that matches a field present in the `SaQC` object, that fields index will be used as new index of `field` * If an `pd.index` object is passed, that will be the new index of `field`">
                    <validator type="empty_field"/>
                  </param>
                </when>
              </conditional>
              <param argument="method" type="select" value="match" optional="true" label="method" help="Determines which of the origins indexes periods to comprise into the calculation of a new flag and a new data value at any period of the new index.  * Aggregations Reindexer. Aggregations are data and flags independent, (pure) index selection methods: * `'bagg'`/`'fagg'`:  backwards/forwards aggregation . Any new index period gets assigned an aggregation of the values at periods in the original index, that lie between itself and its successor/predecessor. * `'nagg'`:  nearest aggregation : Any new index period gets assigned an aggregation of the values at periods in the original index between its direcet predecessor and successor, it is the nearest neighbor to. * Rolling reindexer. Rolling reindexers are equal to aggregations, when projecting between regular and irregular sampling grids forth and back. But due to there simple rolling window construction, they are easier to comprehend, predict and parametrize. On the downside, they are much more expensive computationally and Also, periods can get included in the aggregation to multpiple target periods, (when rolling windows overlap). * `'broll'`/`'froll'`: Any new index period gets assigned an aggregation of all the values at periods of the original index, that fall into a directly preceeding/succeeding window of size `reindex_window`. * Shifts. Shifting methods are shortcuts for aggregation reindex methods, combined with selecting 'last' or 'first' as the `data_aggregation` method. Therefor, both, the `flags_aggregation` and the `data_aggregation` are ignored when using a `shift` reindexer. Also, periods where the data evaluates to `NaN` are dropped before shift index selection. * `'bshift'`/`fshift`:  backwards/forwards shift . Any new index period gets assigned the first/last valid (not a data NaN) value it succeeds/preceeds * `'nshift'`:  nearest shift : Any new index period gets assigned the value of its closest neighbor in the original index. * Pillar point Mappings. Index selection method designed to select indices suitable for linearly interpolating index values from surrounding pillar points in the original index, or inverting such a selection. Periods where the data evaluates to `NaN`, are dropped from consideration. * `'mshift'`:  Merge  predecessors and successors. Any new index period gets assigned an aggregation/interpolation comprising the last and the next valid period in the original index. * `'sshift'`:  Split -map values onto predecessors and successors. Same as `mshift`, but with a correction that prevents missing value flags from being mapped to continuous data chunk bounds. * Inversion of last method: try to select the method, that * `'invert``">
                <option value="fagg">fagg</option>
                <option value="bagg">bagg</option>
                <option value="nagg">nagg</option>
                <option value="froll">froll</option>
                <option value="broll">broll</option>
                <option value="nroll">nroll</option>
                <option value="fshift">fshift</option>
                <option value="bshift">bshift</option>
                <option value="nshift">nshift</option>
                <option value="match">match</option>
                <option value="sshift">sshift</option>
                <option value="mshift">mshift</option>
                <option value="invert">invert</option>
              </param>
              <conditional name="tolerance_cond" label="tolerance">
                <param name="tolerance_selector" type="select" label="Choose type for 'tolerance'" help="Limiting the distance, values can be shifted or comprised into aggregation">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">Offsetlike</option>
                </param>
                <when value="type_0">
                  <param argument="tolerance" type="text" optional="true" label="tolerance" help="Limiting the distance, values can be shifted or comprised into aggregation (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="tolerance" type="text" label="tolerance" help="Limiting the distance, values can be shifted or comprised into aggregation">
                    <validator type="regex" message="Please enter a valid Timedelta string (e.g., '30min', '2H', '1D')."><![CDATA[^\s*-?\d+(\.\d+)?\s*(D|H|T|S|L|U|N|days?|hours?|minutes?|seconds?|weeks?|milliseconds?|microseconds?|nanoseconds?)\s*$]]></validator>
                  </param>
                </when>
              </conditional>
              <conditional name="data_aggregation_cond" label="data_aggregation">
                <param name="data_aggregation_selector" type="select" label="Choose type for 'data_aggregation'" help="Function string or custom Function, determining how to aggregate new data values from the values at the periods selected according to the `index_selection_method`. If a scalar value is passed, the new data series will just evaluate to that scalar at any new index">
                  <option value="type_0">Agg Func Literals</option>
                  <option value="type_1">Float</option>
                </param>
                <when value="type_0">
                  <param argument="data_aggregation" type="select" optional="true" label="data_aggregation" help="Function string or custom Function, determining how to aggregate new data values from the values at the periods selected according to the `index_selection_method`. If a scalar value is passed, the new data series will just evaluate to that scalar at any new index">
                    <option value="sum">sum</option>
                    <option value="mean">mean</option>
                    <option value="median">median</option>
                    <option value="min">min</option>
                    <option value="max">max</option>
                    <option value="last">last</option>
                    <option value="first">first</option>
                    <option value="std">std</option>
                    <option value="var">var</option>
                    <option value="count">count</option>
                    <option value="sem">sem</option>
                    <option value="linear">linear</option>
                    <option value="time">time</option>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="data_aggregation" type="float" optional="true" label="data_aggregation" help="Function string or custom Function, determining how to aggregate new data values from the values at the periods selected according to the `index_selection_method`. If a scalar value is passed, the new data series will just evaluate to that scalar at any new index"/>
                </when>
              </conditional>
              <conditional name="flags_aggregation_cond" label="flags_aggregation">
                <param name="flags_aggregation_selector" type="select" label="Choose type for 'flags_aggregation'" help="Function string or custom Function, determining how to aggregate new flags values from the values at the periods selected according to the `index_selection_method`. If a scalar value is passed, the new flags series will just evaluate to that scalar at any new index">
                  <option value="type_0">Agg Func Literals</option>
                  <option value="type_1">Float</option>
                </param>
                <when value="type_0">
                  <param argument="flags_aggregation" type="select" optional="true" label="flags_aggregation" help="Function string or custom Function, determining how to aggregate new flags values from the values at the periods selected according to the `index_selection_method`. If a scalar value is passed, the new flags series will just evaluate to that scalar at any new index">
                    <option value="sum">sum</option>
                    <option value="mean">mean</option>
                    <option value="median">median</option>
                    <option value="min">min</option>
                    <option value="max">max</option>
                    <option value="last">last</option>
                    <option value="first">first</option>
                    <option value="std">std</option>
                    <option value="var">var</option>
                    <option value="count">count</option>
                    <option value="sem">sem</option>
                    <option value="linear">linear</option>
                    <option value="time">time</option>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="flags_aggregation" type="float" optional="true" label="flags_aggregation" help="Function string or custom Function, determining how to aggregate new flags values from the values at the periods selected according to the `index_selection_method`. If a scalar value is passed, the new flags series will just evaluate to that scalar at any new index"/>
                </when>
              </conditional>
              <param argument="broadcast" type="boolean" label="broadcast" help="Weather to propagate aggregation result to full reindex window when using aggregation reindexer. (as opposed to only assign to next/previous/closest)" checked="false" truevalue="broadcast" falsevalue=""/>
              <param argument="squeeze" type="boolean" label="squeeze" help="" checked="false" truevalue="squeeze" falsevalue=""/>
              <param argument="override" type="boolean" label="override" help="" checked="false" truevalue="override" falsevalue=""/>
            </when>
            <when value="resample">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="freq_cond" label="freq">
                <param name="freq_selector" type="select" label="Choose type for 'freq'" help="Offset string. Sampling rate of the target frequency grid">
                  <option value="type_0">Frequency String</option>
                  <option value="type_1">Pd.Timedelta</option>
                </param>
                <when value="type_0">
                  <param argument="freq" type="text" label="freq" help="Offset string. Sampling rate of the target frequency grid (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="freq" type="text" label="freq" help="Offset string. Sampling rate of the target frequency grid">
                    <validator type="regex" message="Please enter a valid Timedelta string (e.g., '30min', '2H', '1D')."><![CDATA[^\s*-?\d+(\.\d+)?\s*(D|H|T|S|L|U|N|days?|hours?|minutes?|seconds?|weeks?|milliseconds?|microseconds?|nanoseconds?)\s*$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
              </conditional>
              <param argument="method" type="select" value="bagg" optional="true" label="method" help="Specifies which intervals to be aggregated for a certain timestamp. (preceding, succeeding or  surrounding  interval). See description above for more details">
                <option value="fagg">fagg</option>
                <option value="bagg">bagg</option>
                <option value="nagg">nagg</option>
              </param>
              <param argument="maxna" type="integer" optional="true" label="maxna" help="Maximum number of allowed ``NaN``s in a resampling interval. If exceeded, the aggregation of the interval evaluates to ``NaN``" min="0"/>
              <param argument="maxna_group" type="integer" optional="true" label="maxna_group" help="Same as `maxna` but for consecutive NaNs" min="0"/>
              <param argument="squeeze" type="boolean" label="squeeze" help="" checked="false" truevalue="squeeze" falsevalue=""/>
            </when>
          </conditional>
        </when>
        <when value="residuals">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="calculatePolynomialResiduals">calculatePolynomialResiduals: Fits a polynomial model to the data and calculate the residuals</option>
              <option value="calculateRollingResiduals">calculateRollingResiduals: Calculate the diff of a rolling-window function and the data</option>
            </param>
            <when value="calculatePolynomialResiduals">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="The size of the window you want to use for fitting. If an integer is passed, the size refers to the number of periods for every fitting window. If an offset string is passed, the size refers to the total temporal extension. The window will be centered around the vaule-to-be-fitted. For regularly sampled timeseries the period number will be casted down to an odd number if even">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">(Integer &gt; 0)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" label="window" help="The size of the window you want to use for fitting. If an integer is passed, the size refers to the number of periods for every fitting window. If an offset string is passed, the size refers to the total temporal extension. The window will be centered around the vaule-to-be-fitted. For regularly sampled timeseries the period number will be casted down to an odd number if even (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" label="window" help="The size of the window you want to use for fitting. If an integer is passed, the size refers to the number of periods for every fitting window. If an offset string is passed, the size refers to the total temporal extension. The window will be centered around the vaule-to-be-fitted. For regularly sampled timeseries the period number will be casted down to an odd number if even" min="0"/>
                </when>
              </conditional>
              <param argument="order" type="integer" label="order" help="The degree of the polynomial used for fitting"/>
              <param argument="min_periods" type="integer" value="0" optional="true" label="min_periods" help="The minimum number of periods, that has to be available in every values fitting surrounding for the polynomial fit to be performed. If there are not enough values, np.nan gets assigned. Default (0) results in fitting regardless of the number of values present (results in overfitting for too sparse intervals). To automatically set the minimum number of periods to the number of values in an offset defined window size, pass np.nan"/>
            </when>
            <when value="calculateRollingResiduals">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="The size of the window you want to roll with. If an integer is passed, the size refers to the number of periods for every fitting window. If an offset string is passed, the size refers to the total temporal extension. For regularly sampled timeseries, the period number will be casted down to an odd number if ``center=True``">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">(Integer &gt; 0)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" label="window" help="The size of the window you want to roll with. If an integer is passed, the size refers to the number of periods for every fitting window. If an offset string is passed, the size refers to the total temporal extension. For regularly sampled timeseries, the period number will be casted down to an odd number if ``center=True`` (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" label="window" help="The size of the window you want to roll with. If an integer is passed, the size refers to the number of periods for every fitting window. If an offset string is passed, the size refers to the total temporal extension. For regularly sampled timeseries, the period number will be casted down to an odd number if ``center=True``" min="0"/>
                </when>
              </conditional>
              <param argument="min_periods" type="integer" value="0" optional="true" label="min_periods" help="The minimum number of periods to get a valid value" min="0"/>
              <param argument="center" type="boolean" label="center" help="If True, center the rolling window" checked="false" truevalue="center" falsevalue=""/>
            </when>
          </conditional>
        </when>
        <when value="rolling">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="rolling">rolling: Evaluate a function at all shifts of a fixed-size window ( rolling window application )</option>
            </param>
            <when value="rolling">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <conditional name="window_cond" label="window">
                <param name="window_selector" type="select" label="Choose type for 'window'" help="int or str Size of the rolling window. If an integer, it determines the window size as the number of periods it has to contain at every shift. If an offset string, it determines the window size as its constant temporal extension. For regularly sampled data, the period number is rounded down to an odd number in case ``center``  is True">
                  <option value="type_0">Offset String</option>
                  <option value="type_1">(Integer &gt; 0)</option>
                </param>
                <when value="type_0">
                  <param argument="window" type="text" label="window" help="int or str Size of the rolling window. If an integer, it determines the window size as the number of periods it has to contain at every shift. If an offset string, it determines the window size as its constant temporal extension. For regularly sampled data, the period number is rounded down to an odd number in case ``center``  is True (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                    <validator type="empty_field"/>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="window" type="integer" label="window" help="int or str Size of the rolling window. If an integer, it determines the window size as the number of periods it has to contain at every shift. If an offset string, it determines the window size as its constant temporal extension. For regularly sampled data, the period number is rounded down to an odd number in case ``center``  is True" min="0"/>
                </when>
              </conditional>
              <param argument="target" type="data_column" optional="true" label="target" help="`SaQCFields` | `newSaQCFields` , optional Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="func" type="select" value="mean" optional="true" label="func" help="callable or str Function to apply to window at each shift. Can either be a custom callable, expecting a ``pandas.Series`` object as its input, or a literal from the following list:  -  sum     : Sum of values in the window -  mean    : Average of values -  median  : Median -  min     : Minimum -  max     : Maximum -  std     : Standard deviation -  var     : Variance -  skew    : Skewness -  kurt    : Kurtosis -  count   : Number of non-NA observations in the window">
                <option value="sum">sum</option>
                <option value="mean">mean</option>
                <option value="median">median</option>
                <option value="min">min</option>
                <option value="max">max</option>
                <option value="std">std</option>
                <option value="var">var</option>
                <option value="skew">skew</option>
                <option value="kurt">kurt</option>
                <option value="count">count</option>
              </param>
              <param argument="min_periods" type="integer" value="0" optional="true" label="min_periods" help="int Minimum number of valid observations in the window required to calculate a value" min="0"/>
              <param argument="center" type="boolean" label="center" help="bool If ``True``, function results are assigned to the timestamp at the center of the windows; if ``False``, they are assigned to the highest timestamp in the windows" checked="false" truevalue="center" falsevalue=""/>
            </when>
          </conditional>
        </when>
        <when value="scores">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="assignKNNScore">assignKNNScore: Score datapoints by an aggregation of the distances to their `k` nearest neighbors</option>
              <option value="assignLOF">assignLOF: Assign Local Outlier Factor (LOF)</option>
              <option value="assignUniLOF">assignUniLOF: Assign  univariate  Local Outlier Factor (LOF) or  inivariate  Local Outlier Probability (LOP)</option>
              <option value="assignZScore">assignZScore: Calculate (rolling) Zscores</option>
            </param>
            <when value="assignKNNScore">
              <param argument="field" type="data_column" label="field" help="List of variables names to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="target" type="data_column" label="target" help="`SaQCFields` | `newSaQCFields` Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="n" type="integer" value="10" optional="true" label="n" help=": The number of nearest neighbors to which the distance is comprised in every datapoints scoring calculation" min="0"/>
              <conditional name="freq_cond" label="freq">
                <param name="freq_selector" type="select" label="Choose type for 'freq'" help="Determines the segmentation of the data into partitions, the kNN algorithm is applied onto individually.  * ``np.inf``: Apply Scoring on whole data set at once * ``x``   0 : Apply scoring on successive data chunks of periods length ``x`` * Offset String : Apply scoring on successive partitions of temporal extension matching the passed offset string">
                  <option value="type_0">(Float &gt;= 0)</option>
                  <option value="type_1">Frequency String</option>
                </param>
                <when value="type_0">
                  <param argument="freq" type="float" optional="true" label="freq" help="Determines the segmentation of the data into partitions, the kNN algorithm is applied onto individually.  * ``np.inf``: Apply Scoring on whole data set at once * ``x``   0 : Apply scoring on successive data chunks of periods length ``x`` * Offset String : Apply scoring on successive partitions of temporal extension matching the passed offset string" min="0"/>
                </when>
                <when value="type_1">
                  <param argument="freq" type="text" optional="true" label="freq" help="Determines the segmentation of the data into partitions, the kNN algorithm is applied onto individually.  * ``np.inf``: Apply Scoring on whole data set at once * ``x``   0 : Apply scoring on successive data chunks of periods length ``x`` * Offset String : Apply scoring on successive partitions of temporal extension matching the passed offset string (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
              </conditional>
              <param argument="min_periods" type="integer" value="2" optional="true" label="min_periods" help="The minimum number of periods that have to be present in a window for the kNN scoring to be applied. If the number of periods present is below `min_periods`, the score for the datapoints in that window will be np.nan" min="0"/>
              <param argument="algorithm" type="select" value="ball_tree" optional="true" label="algorithm" help="The search algorithm to find each datapoints k nearest neighbors. The keyword just gets passed on to the underlying sklearn method. See reference [1] for more information on the algorithm">
                <option value="ball_tree">ball_tree</option>
                <option value="kd_tree">kd_tree</option>
                <option value="brute">brute</option>
                <option value="auto">auto</option>
              </param>
              <param argument="metric" type="text" value="minkowski" label="metric" help="The metric the distances to any datapoints neighbors is computed with. The default of `metric` together with the default of `p` result in the euclidian to be applied. The keyword just gets passed on to the underlying sklearn method. See reference [1] for more information on the algorithm"/>
              <param argument="p" type="integer" value="2" optional="true" label="p" help=": The grade of the metrice specified by parameter `metric`. The keyword just gets passed on to the underlying sklearn method. See reference [1] for more information on the algorithm" min="0"/>
            </when>
            <when value="assignLOF">
              <param argument="field" type="data_column" label="field" help="List of variables names to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="target" type="data_column" label="target" help="`SaQCFields` | `newSaQCFields` Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="n" type="integer" value="20" optional="true" label="n" help="Number of periods to be included into the LOF calculation. Defaults to `20`, which is a value found to be suitable in the literature" min="0"/>
              <conditional name="freq_cond" label="freq">
                <param name="freq_selector" type="select" label="Choose type for 'freq'" help="Determines the segmentation of the data into partitions, the kNN algorithm is applied onto individually">
                  <option value="type_0">(Float &gt; 0)</option>
                  <option value="type_1">Frequency String</option>
                </param>
                <when value="type_0">
                  <param argument="freq" type="float" optional="true" label="freq" help="Determines the segmentation of the data into partitions, the kNN algorithm is applied onto individually" min="0"/>
                </when>
                <when value="type_1">
                  <param argument="freq" type="text" optional="true" label="freq" help="Determines the segmentation of the data into partitions, the kNN algorithm is applied onto individually (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
              </conditional>
              <param argument="min_periods" type="integer" value="2" optional="true" label="min_periods" help="" min="0"/>
              <param argument="algorithm" type="select" value="ball_tree" optional="true" label="algorithm" help="Algorithm used for calculating the `n`-nearest neighbors needed for LOF calculation">
                <option value="ball_tree">ball_tree</option>
                <option value="kd_tree">kd_tree</option>
                <option value="brute">brute</option>
                <option value="auto">auto</option>
              </param>
              <param argument="p" type="integer" value="2" optional="true" label="p" help="Degree of the metric ( Minkowski ), according to wich distance to neighbors is determined. Most important values are:  * `1` - Manhatten Metric * `2` - Euclidian Metric" min="0"/>
            </when>
            <when value="assignUniLOF">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="n" type="integer" value="20" optional="true" label="n" help="Number of periods to be included into the LOF calculation. Defaults to `20`, which is a value found to be suitable in the literature.  * `n` determines the  locality  of an observation (its `n` nearest neighbors) and sets the upper limit of values of an outlier clusters (i.e. consecutive outliers). Outlier clusters of size greater than `n/2` may not be detected reliably. * The larger `n`, the lesser the algorithm's sensitivity to local outliers and small or singleton outliers points. Higher values greatly increase numerical costs" min="0"/>
              <param argument="algorithm" type="select" value="ball_tree" optional="true" label="algorithm" help="Algorithm used for calculating the `n`-nearest neighbors needed for LOF calculation">
                <option value="ball_tree">ball_tree</option>
                <option value="kd_tree">kd_tree</option>
                <option value="brute">brute</option>
                <option value="auto">auto</option>
              </param>
              <param argument="p" type="integer" value="1" optional="true" label="p" help="Degree of the metric ( Minkowski ), according to wich distance to neighbors is determined. Most important values are:  * `1` - Manhatten Metric * `2` - Euclidian Metric" min="0"/>
              <conditional name="density_cond" label="density">
                <param name="density_selector" type="select" label="Choose type for 'density'" help="How to calculate the temporal distance/density for the variable-to-be-flagged.  * float - introduces linear density with an increment equal to `density` * Callable - calculates the density by applying the function passed onto the variable to be flagged (passed as Series)">
                  <option value="type_0">Selection</option>
                  <option value="type_1">(Float &gt; 0)</option>
                </param>
                <when value="type_0">
                  <param argument="density" type="select" optional="true" label="density" help="How to calculate the temporal distance/density for the variable-to-be-flagged.  * float - introduces linear density with an increment equal to `density` * Callable - calculates the density by applying the function passed onto the variable to be flagged (passed as Series)">
                    <option value="auto">auto</option>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="density" type="float" optional="true" label="density" help="How to calculate the temporal distance/density for the variable-to-be-flagged.  * float - introduces linear density with an increment equal to `density` * Callable - calculates the density by applying the function passed onto the variable to be flagged (passed as Series)" min="0"/>
                </when>
              </conditional>
              <param argument="fill_na" type="boolean" label="fill_na" help="If True, NaNs in the data are filled with a linear interpolation" checked="false" truevalue="fill_na" falsevalue=""/>
              <param argument="statistical_extent" type="integer" value="1" optional="true" label="statistical_extent" help=""/>
            </when>
            <when value="assignZScore">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="window" type="text" optional="true" label="window" help="Size of the window. can be determined as: * Offset String, denoting the windows temporal extension * Integer, denoting the windows number of periods. * `None` (default), All data points share the same scoring window, which than equals the whole data (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
              </param>
              <param argument="center" type="boolean" label="center" help="Weather or not to center the target value in the scoring window. If `False`, the target value is the last value in the window" checked="false" truevalue="center" falsevalue=""/>
              <param argument="min_periods" type="integer" optional="true" label="min_periods" help="Minimum number of valid meassurements in a scoring window, to consider the resulting score valid" min="0"/>
            </when>
          </conditional>
        </when>
        <when value="tools">
          <conditional name="method_cond" label="Method">
            <param name="method_select" type="select" label="Method">
              <option value="copyField">copyField: Make a copy of the data and flags to a new field</option>
              <option value="dropField">dropField: Drops field from the data and flags</option>
              <option value="flagByClick">flagByClick: Pop up GUI for adding or removing flags by selection of points in the data plot</option>
              <option value="plot">plot: Plot data and flags or store plot to file</option>
              <option value="renameField">renameField: Rename field to the given name</option>
              <option value="selectTime">selectTime: Realizes masking within saqc</option>
            </param>
            <when value="copyField">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="target" type="data_column" label="target" help="`SaQCFields` | `newSaQCFields` Variable name to which the results are written. `target` will be created if it does not exist. Defaults to `field`" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="overwrite" type="boolean" label="overwrite" help="bool Overwrite ``target``, if already existing" checked="false" truevalue="overwrite" falsevalue=""/>
            </when>
            <when value="dropField">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
            </when>
            <when value="flagByClick">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="max_gap" type="text" optional="true" label="max_gap" help="If ``None``, all data points will be connected, resulting in long linear lines, in case of large data gaps. ``NaN`` values will be removed before plotting. If an offset string is passed, only points that have a distance below ``max_gap`` are connected via the plotting line (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
              </param>
              <param argument="gui_mode" type="select" value="GUI" optional="true" label="gui_mode" help="* `` GUI `` (default), spawns TK based pop-up GUI, enabling scrolling and binding for subplots * `` overlay ``, spawns matplotlib based pop-up GUI. May be less conflicting, but does not support scrolling or binding">
                <option value="GUI">GUI</option>
                <option value="overlay">overlay</option>
              </param>
              <param argument="dfilter" type="float" value="255.0" optional="true" label="dfilter" help="`Any`, optional Defines which observations will be masked based on the already existing flags. Any data point with a flag equal or worse to this threshold will be passed as ``NaN`` to the function. Defaults to the ``DFILTER_ALL`` value of the translation scheme"/>
            </when>
            <when value="plot">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="path" type="text" label="path" help="If ``None`` is passed, interactive mode is entered; plots are shown immediatly and a user need to close them manually before execution continues. If a filepath is passed instead, store-mode is entered and the plot is stored unter the passed location"/>
              <param argument="max_gap" type="text" optional="true" label="max_gap" help="If ``None``, all data points will be connected, resulting in long linear lines, in case of large data gaps. ``NaN`` values will be removed before plotting. If an offset string is passed, only points that have a distance below ``max_gap`` are connected via the plotting line (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
              </param>
              <conditional name="mode_cond" label="mode">
                <param name="mode_selector" type="select" label="Choose type for 'mode'" help="How to process multiple variables to be plotted:  * ` oneplot ` : plot all variables with their flags in one axis (default) * ` subplots ` : generate subplot grid where each axis contains one variable plot with associated flags * ` biplot ` : plotting first and second variable in field against each other in a scatter plot  (point cloud)">
                  <option value="type_0">Selection</option>
                  <option value="type_1">Text</option>
                </param>
                <when value="type_0">
                  <param argument="mode" type="select" optional="true" label="mode" help="How to process multiple variables to be plotted:  * ` oneplot ` : plot all variables with their flags in one axis (default) * ` subplots ` : generate subplot grid where each axis contains one variable plot with associated flags * ` biplot ` : plotting first and second variable in field against each other in a scatter plot  (point cloud)">
                    <option value="subplots">subplots</option>
                    <option value="oneplot">oneplot</option>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="mode" type="text" label="mode" help="How to process multiple variables to be plotted:  * ` oneplot ` : plot all variables with their flags in one axis (default) * ` subplots ` : generate subplot grid where each axis contains one variable plot with associated flags * ` biplot ` : plotting first and second variable in field against each other in a scatter plot  (point cloud)"/>
                </when>
              </conditional>
              <conditional name="history_cond" label="history">
                <param name="history_selector" type="select" label="Choose type for 'history'" help="Discriminate the plotted flags with respect to the tests they originate from.  * `` valid ``: Only plot flags, that are not overwritten by subsequent tests. Only list tests in the legend, that actually contributed flags to the overall result. * ``None``: Just plot the resulting flags for one variable, without any historical and/or meta information. * list of strings: List of tests. Plot flags from the given tests, only. * ``complete`` (not recommended, deprecated): Plot all the flags set by any test, independently from them being removed or modified by subsequent modifications. (this means: plotted flags do not necessarily match with flags ultimately assigned to the data)">
                  <option value="type_0">Selection</option>
                  <option value="type_1">List[Str]</option>
                </param>
                <when value="type_0">
                  <param argument="history" type="select" optional="true" label="history" help="Discriminate the plotted flags with respect to the tests they originate from.  * `` valid ``: Only plot flags, that are not overwritten by subsequent tests. Only list tests in the legend, that actually contributed flags to the overall result. * ``None``: Just plot the resulting flags for one variable, without any historical and/or meta information. * list of strings: List of tests. Plot flags from the given tests, only. * ``complete`` (not recommended, deprecated): Plot all the flags set by any test, independently from them being removed or modified by subsequent modifications. (this means: plotted flags do not necessarily match with flags ultimately assigned to the data)">
                    <option value="valid">valid</option>
                    <option value="complete">complete</option>
                  </param>
                </when>
                <when value="type_1">
                  <param argument="history" type="text" label="history" help="Discriminate the plotted flags with respect to the tests they originate from.  * `` valid ``: Only plot flags, that are not overwritten by subsequent tests. Only list tests in the legend, that actually contributed flags to the overall result. * ``None``: Just plot the resulting flags for one variable, without any historical and/or meta information. * list of strings: List of tests. Plot flags from the given tests, only. * ``complete`` (not recommended, deprecated): Plot all the flags set by any test, independently from them being removed or modified by subsequent modifications. (this means: plotted flags do not necessarily match with flags ultimately assigned to the data)" multiple="true"/>
                </when>
              </conditional>
              <conditional name="xscope_cond" label="xscope">
                <param name="xscope_selector" type="select" label="Choose type for 'xscope'" help="Determine a chunk of the data to be plotted. ``xscope`` can be anything, that is a valid argument to the ``pandas.Series.__getitem__`` method">
                  <option value="type_0">Slice</option>
                  <option value="type_1">Offset String</option>
                  <option value="type_2">Text</option>
                </param>
                <when value="type_0">
                  <param name="xscope_start" type="integer" optional="true" label="xscope (start index)" help="Start index of the slice (e.g., 0)." min="0"/>
                  <param name="xscope_end" type="integer" optional="true" label="xscope (end index)" help="End index of the slice (exclusive)." min="0"/>
                </when>
                <when value="type_1">
                  <param argument="xscope" type="text" optional="true" label="xscope" help="Determine a chunk of the data to be plotted. ``xscope`` can be anything, that is a valid argument to the ``pandas.Series.__getitem__`` method (Pandas frequency/offset string, e.g., '1D', '2H30M', 'min', 'W-MON')">
                    <validator type="regex" message="Must be a valid Pandas offset/frequency string (e.g., '1D', '2H30M', 'min', 'W-MON')."><![CDATA[^(\s*(\d+(\.\d+)?)?\s*[A-Za-z]+(?:-[A-Za-z]{3})?\s*)+$]]></validator>
                  </param>
                </when>
                <when value="type_2">
                  <param argument="xscope" type="text" label="xscope" help="Determine a chunk of the data to be plotted. ``xscope`` can be anything, that is a valid argument to the ``pandas.Series.__getitem__`` method"/>
                </when>
              </conditional>
              <conditional name="yscope_cond" label="yscope">
                <param name="yscope_selector" type="select" label="Choose type for 'yscope'" help="Either a tuple of 2 scalars that determines all plots' y-view limits, or a list of those tuples, determining the different variables y-view limits (must match number of variables) or a dictionary with variables as keys and the y-view tuple as values">
                  <option value="type_0">List of Y-Ranges</option>
                  <option value="type_1">Single Y-Range</option>
                </param>
                <when value="type_0">
                  <repeat name="yscope" title="yscope" help="Either a tuple of 2 scalars that determines all plots' y-view limits, or a list of those tuples, determining the different variables y-view limits (must match number of variables) or a dictionary with variables as keys and the y-view tuple as values">
                    <param name="yscope_min" type="float" label="yscope_min"/>
                    <param name="yscope_max" type="float" label="yscope_max"/>
                  </repeat>
                </when>
                <when value="type_1">
                  <param name="yscope_min" type="float" optional="true" label="yscope_min"/>
                  <param name="yscope_max" type="float" optional="true" label="yscope_max"/>
                </when>
              </conditional>
              <param argument="dfilter" type="float" value="inf" optional="true" label="dfilter" help="`Any`, optional Defines which observations will be masked based on the already existing flags. Any data point with a flag equal or worse to this threshold will be passed as ``NaN`` to the function. Defaults to the ``DFILTER_ALL`` value of the translation scheme"/>
            </when>
            <when value="renameField">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="new_name" type="text" label="new_name" help="str New name for the field">
                <validator type="empty_field"/>
              </param>
            </when>
            <when value="selectTime">
              <param argument="field" type="data_column" label="field" help="Variable to process" data_ref="data" display="checkboxes" multiple="true"/>
              <param argument="mode" type="select" label="mode" help="The masking mode. -  periodic : parameters  period_start ,  end  are evaluated to generate a periodical mask -  mask_var : data[mask_var] is expected to be a boolean valued timeseries and is used as mask">
                <option value="periodic">periodic</option>
                <option value="selection_field">selection_field</option>
              </param>
              <param argument="selection_field" type="text" label="selection_field" help="Only effective if mode ==  mask_var  Fieldname of the column, holding the data that is to be used as mask. (must be boolean series) Neither the series` length nor its labels have to match data[field]`s index and length. An inner join of the indices will be calculated and values get masked where the values of the inner join are ``True``"/>
              <param argument="start" type="text" label="start" help="Only effective if mode ==  seasonal  String denoting starting point of every period. Formally, it has to be a truncated instance of  mm-ddTHH:MM:SS . Has to be of same length as `end` parameter. See examples section below for some examples"/>
              <param argument="end" type="text" label="end" help="Only effective if mode ==  periodic  String denoting starting point of every period. Formally, it has to be a truncated instance of  mm-ddTHH:MM:SS . Has to be of same length as `end` parameter. See examples section below for some examples"/>
              <param argument="closed" type="boolean" label="closed" help="Wheather or not to include the mask defining bounds to the mask" checked="false" truevalue="closed" falsevalue=""/>
            </when>
          </conditional>
        </when>
        <when value="transformation">
          <param name="transformation_no_methods_conditional" type="text" value="Could not generate method selection for module 'transformation'." label="Notice"/>
        </when>
      </conditional>
    </repeat>
  </inputs>
  <outputs>
    <data name="output" format="csv" label="${tool.name} on ${on_string}: Processed Data" from_work_dir="output.csv" hidden="false"/>
    <collection name="plots" type="list" label="${tool.name} on ${on_string}: Plots (if any generated)">
      <discover_datasets pattern="(?P&lt;name&gt;.*)\.png" ext="png" visible="true"/>
    </collection>
    <data name="config_out" format="txt" label="${tool.name} on ${on_string}: Generated SaQC Configuration" from_work_dir="config.csv" hidden="false"/>
  </outputs>
  <expand macro="saqc_tests"/>
  <help><![CDATA[This tool provides access to SaQC functions for quality control of time series data. Select a module and method, then configure its parameters.]]></help>
  <expand macro="citations"/>
</tool>

